{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "As I am using google colab for model building, connecting colab session with gdrive"
      ],
      "metadata": {
        "id": "TPH66a0flaTs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bY6ueGiJ2rFJ",
        "outputId": "a49fc089-292a-4bbb-f6aa-2f08f3e8b8d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking if the path is correct"
      ],
      "metadata": {
        "id": "rFQvjOOglt8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "path= '/content/drive/MyDrive/Colab Notebooks/NLP_tranformers/data_clean.csv'\n",
        "print(os.path.isfile(path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9kvkFCN2xv-",
        "outputId": "cdafe43d-1ccb-448e-c0bc-6a1bc004095d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()"
      ],
      "metadata": {
        "id": "OZRRAn_SLWbB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(path)\n",
        "df = df[['text','label']]\n",
        "df['text'] = df['text'].replace('\\n',' ', regex=True)\n",
        "df.rename(columns={'text': 'article', 'label': 'category'}, inplace=True)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5TL_kQP_3Avf",
        "outputId": "289a1761-0cb1-4e25-fc9e-8b226fea1035"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5ab81f15-1bca-4aaf-8fba-737881da09fd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ad sales boost time warner profit  quarterly p...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dollar gains on greenspan speech  the dollar h...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>yukos unit buyer faces loan claim  the owners ...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>high fuel prices hit ba's profits  british air...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pernod takeover talk lifts domecq  shares in u...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ab81f15-1bca-4aaf-8fba-737881da09fd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5ab81f15-1bca-4aaf-8fba-737881da09fd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5ab81f15-1bca-4aaf-8fba-737881da09fd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                             article  category\n",
              "0  ad sales boost time warner profit  quarterly p...  business\n",
              "1  dollar gains on greenspan speech  the dollar h...  business\n",
              "2  yukos unit buyer faces loan claim  the owners ...  business\n",
              "3  high fuel prices hit ba's profits  british air...  business\n",
              "4  pernod takeover talk lifts domecq  shares in u...  business"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['category'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdML7RE3mAg7",
        "outputId": "913f3b3a-ce5d-4381-d06e-0a79e2d494b8"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "business         495\n",
              "sport            495\n",
              "politics         403\n",
              "entertainment    378\n",
              "tech             342\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding the categorical targets and creating a new column with encoded values"
      ],
      "metadata": {
        "id": "PPgGKL1tl3kQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "possible_labels = df.category.unique()\n",
        "\n",
        "label_dict = {}\n",
        "for index, possible_label in enumerate(possible_labels):\n",
        "    label_dict[possible_label] = index\n",
        "label_dict"
      ],
      "metadata": {
        "id": "cy7OnoVDR1Io",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c87ec3f-9e0e-4b69-d665-6fec4d5271a7"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'business': 0, 'entertainment': 1, 'politics': 2, 'sport': 3, 'tech': 4}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'] = df.category.replace(label_dict)\n",
        "df['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NP0NL5eDCsi",
        "outputId": "e7b2f445-dd4a-4771-e244-29a5877f8cac"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3    495\n",
              "0    495\n",
              "2    403\n",
              "1    378\n",
              "4    342\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data splitting"
      ],
      "metadata": {
        "id": "YYeBqg4PmJEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.index.values, \n",
        "                                                  df.label.values, \n",
        "                                                  test_size= 0.2, \n",
        "                                                  random_state=100, \n",
        "                                                  stratify=df.label.values)\n",
        "\n",
        "df['data_type'] = ['not_set']*df.shape[0]\n",
        "\n",
        "df.loc[X_train, 'data_type'] = 'train'\n",
        "df.loc[X_test, 'data_type'] = 'test'\n",
        "\n",
        "df.groupby(['category', 'label', 'data_type']).count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "UYUwVg_ZuSB1",
        "outputId": "61155939-3962-4666-9d17-6b373f2b158d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3a0392a6-02b0-4d07-b1c0-e0b766d34da5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>article</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>category</th>\n",
              "      <th>label</th>\n",
              "      <th>data_type</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">business</th>\n",
              "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
              "      <th>test</th>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train</th>\n",
              "      <td>396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">entertainment</th>\n",
              "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
              "      <th>test</th>\n",
              "      <td>76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train</th>\n",
              "      <td>302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">politics</th>\n",
              "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
              "      <th>test</th>\n",
              "      <td>81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train</th>\n",
              "      <td>322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">sport</th>\n",
              "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
              "      <th>test</th>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train</th>\n",
              "      <td>396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">tech</th>\n",
              "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
              "      <th>test</th>\n",
              "      <td>68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train</th>\n",
              "      <td>274</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a0392a6-02b0-4d07-b1c0-e0b766d34da5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3a0392a6-02b0-4d07-b1c0-e0b766d34da5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3a0392a6-02b0-4d07-b1c0-e0b766d34da5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                               article\n",
              "category      label data_type         \n",
              "business      0     test            99\n",
              "                    train          396\n",
              "entertainment 1     test            76\n",
              "                    train          302\n",
              "politics      2     test            81\n",
              "                    train          322\n",
              "sport         3     test            99\n",
              "                    train          396\n",
              "tech          4     test            68\n",
              "                    train          274"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train, test =  train_test_split(df, test_size = 0.2, random_state = 100,stratify=df.label.values)"
      ],
      "metadata": {
        "id": "2EPMuo5hSLvv"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['category'].value_counts().plot(kind = 'bar')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "FBvIQf5wSOoH",
        "outputId": "4d65438f-ac9b-42e8-dac0-50b3ffac3d3d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa58a993e50>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "id": "5OptFwP_7rW5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "8822ab88-db6f-4e4d-a769-9a4c708032c0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-55c0e250-705c-48ae-b203-5ed258008710\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article</th>\n",
              "      <th>category</th>\n",
              "      <th>label</th>\n",
              "      <th>data_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2108</th>\n",
              "      <td>broadband fuels online expression  fast web ac...</td>\n",
              "      <td>tech</td>\n",
              "      <td>4</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517</th>\n",
              "      <td>famed music director viotti dies  conductor ma...</td>\n",
              "      <td>entertainment</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>crisis 'ahead in social sciences'  a national ...</td>\n",
              "      <td>politics</td>\n",
              "      <td>2</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>626</th>\n",
              "      <td>sir paul rocks super bowl crowds  sir paul mcc...</td>\n",
              "      <td>entertainment</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>978</th>\n",
              "      <td>howard attacks cost of asylum  michael howard ...</td>\n",
              "      <td>politics</td>\n",
              "      <td>2</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-55c0e250-705c-48ae-b203-5ed258008710')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-55c0e250-705c-48ae-b203-5ed258008710 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-55c0e250-705c-48ae-b203-5ed258008710');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                article  ... data_type\n",
              "2108  broadband fuels online expression  fast web ac...  ...     train\n",
              "517   famed music director viotti dies  conductor ma...  ...     train\n",
              "888   crisis 'ahead in social sciences'  a national ...  ...     train\n",
              "626   sir paul rocks super bowl crowds  sir paul mcc...  ...     train\n",
              "978   howard attacks cost of asylum  michael howard ...  ...     train\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "izAfN8_A7wTe",
        "outputId": "79b8254e-3ea6-4bff-fab9-2ebec32107b1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c229be97-74b4-44c6-b649-de8770bd0538\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article</th>\n",
              "      <th>category</th>\n",
              "      <th>label</th>\n",
              "      <th>data_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>646</th>\n",
              "      <td>outkast win at mtv europe awards  us hip-hop d...</td>\n",
              "      <td>entertainment</td>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1734</th>\n",
              "      <td>faultless federer has no equal  roger federer ...</td>\n",
              "      <td>sport</td>\n",
              "      <td>3</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>830</th>\n",
              "      <td>us composer recreates bach score  a us musicol...</td>\n",
              "      <td>entertainment</td>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>542</th>\n",
              "      <td>'landmark movies' of 2004 hailed  us film prof...</td>\n",
              "      <td>entertainment</td>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1268</th>\n",
              "      <td>tories urge 'change at the top'  tory delegate...</td>\n",
              "      <td>politics</td>\n",
              "      <td>2</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c229be97-74b4-44c6-b649-de8770bd0538')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c229be97-74b4-44c6-b649-de8770bd0538 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c229be97-74b4-44c6-b649-de8770bd0538');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                article  ... data_type\n",
              "646   outkast win at mtv europe awards  us hip-hop d...  ...      test\n",
              "1734  faultless federer has no equal  roger federer ...  ...      test\n",
              "830   us composer recreates bach score  a us musicol...  ...      test\n",
              "542   'landmark movies' of 2004 hailed  us film prof...  ...      test\n",
              "1268  tories urge 'change at the top'  tory delegate...  ...      test\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data preprcessing using pretrained transformer architectures (BERT) from tensorflow hub"
      ],
      "metadata": {
        "id": "R0FtOjrXmaQb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "#import keras\n",
        "#import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow import keras\n",
        "import logging\n",
        "logging.basicConfig(level=logging.INFO)"
      ],
      "metadata": {
        "id": "gdq42uw47vVl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --quiet https://raw.githubusercontent.com/google-research/bert/master/tokenization.py\n",
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aNX_gBBFvO1",
        "outputId": "c222f0b8-8c4c-4a51-a993-14ba5fe76d4d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing tokenization class from bert official library and other dependencies\n",
        "!wget --quiet https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py\n",
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKW-Cb2k8gKC",
        "outputId": "a4c5f903-b611-44fd-c122-2109ae89489e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 5.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==1.15.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9-ndYCddJih_",
        "outputId": "6bbadaa5-021c-42f0-e5bc-468efa2841d5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==1.15.0\n",
            "  Downloading tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3 MB 25 kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.12.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.13.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.19.5)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.2.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 43.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.17.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.43.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.37.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.3.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 17.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (3.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (4.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.7.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15.0) (1.5.2)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=b049f7a7a7878640f29eb78355386654ebd9bb2d7d057d42be853ee74b47ea96\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.7.0\n",
            "    Uninstalling tensorflow-estimator-2.7.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.7.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.7.0\n",
            "    Uninstalling tensorboard-2.7.0:\n",
            "      Successfully uninstalled tensorboard-2.7.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.7.0\n",
            "    Uninstalling tensorflow-2.7.0:\n",
            "      Successfully uninstalled tensorflow-2.7.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.15.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "kapre 0.3.6 requires tensorflow>=2.0.0, but you have tensorflow 1.15.0 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "tensorboard",
                  "tensorflow",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tokenization"
      ],
      "metadata": {
        "id": "WEiKDlE39AoY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now start with the pretrained BERT. In this case we will use the bert_uncased_L-12_H-768_A-12/2 model. We will be using the vocab.txt file in the model to map the words in the dataset to indexes. Also the loaded BERT model is trained on uncased/lowercase data and hence the data we feed to train the model should also be of lowercase.\n",
        "\n",
        "The following code block loads the pre-trained BERT model and initializers a tokenizer object for tokenizing the texts."
      ],
      "metadata": {
        "id": "sbOpsv-jmko7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf. __version__) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FpF5J5sG4ZA",
        "outputId": "09d9650e-2e43-4e9f-b454-8d6d92014cb0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# coding=utf-8\n",
        "# Copyright 2018 The Google AI Language Team Authors.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\"\"\"Tokenization classes.\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import collections\n",
        "import re\n",
        "import unicodedata\n",
        "import six\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def validate_case_matches_checkpoint(do_lower_case, init_checkpoint):\n",
        "  \"\"\"Checks whether the casing config is consistent with the checkpoint name.\"\"\"\n",
        "\n",
        "  # The casing has to be passed in by the user and there is no explicit check\n",
        "  # as to whether it matches the checkpoint. The casing information probably\n",
        "  # should have been stored in the bert_config.json file, but it's not, so\n",
        "  # we have to heuristically detect it to validate.\n",
        "\n",
        "  if not init_checkpoint:\n",
        "    return\n",
        "\n",
        "  m = re.match(\"^.*?([A-Za-z0-9_-]+)/bert_model.ckpt\", init_checkpoint)\n",
        "  if m is None:\n",
        "    return\n",
        "\n",
        "  model_name = m.group(1)\n",
        "\n",
        "  lower_models = [\n",
        "      \"uncased_L-24_H-1024_A-16\", \"uncased_L-12_H-768_A-12\",\n",
        "      \"multilingual_L-12_H-768_A-12\", \"chinese_L-12_H-768_A-12\"\n",
        "  ]\n",
        "\n",
        "  cased_models = [\n",
        "      \"cased_L-12_H-768_A-12\", \"cased_L-24_H-1024_A-16\",\n",
        "      \"multi_cased_L-12_H-768_A-12\"\n",
        "  ]\n",
        "\n",
        "  is_bad_config = False\n",
        "  if model_name in lower_models and not do_lower_case:\n",
        "    is_bad_config = True\n",
        "    actual_flag = \"False\"\n",
        "    case_name = \"lowercased\"\n",
        "    opposite_flag = \"True\"\n",
        "\n",
        "  if model_name in cased_models and do_lower_case:\n",
        "    is_bad_config = True\n",
        "    actual_flag = \"True\"\n",
        "    case_name = \"cased\"\n",
        "    opposite_flag = \"False\"\n",
        "\n",
        "  if is_bad_config:\n",
        "    raise ValueError(\n",
        "        \"You passed in `--do_lower_case=%s` with `--init_checkpoint=%s`. \"\n",
        "        \"However, `%s` seems to be a %s model, so you \"\n",
        "        \"should pass in `--do_lower_case=%s` so that the fine-tuning matches \"\n",
        "        \"how the model was pre-training. If this error is wrong, please \"\n",
        "        \"just comment out this check.\" % (actual_flag, init_checkpoint,\n",
        "                                          model_name, case_name, opposite_flag))\n",
        "\n",
        "\n",
        "def convert_to_unicode(text):\n",
        "  \"\"\"Converts `text` to Unicode (if it's not already), assuming utf-8 input.\"\"\"\n",
        "  if six.PY3:\n",
        "    if isinstance(text, str):\n",
        "      return text\n",
        "    elif isinstance(text, bytes):\n",
        "      return text.decode(\"utf-8\", \"ignore\")\n",
        "    else:\n",
        "      raise ValueError(\"Unsupported string type: %s\" % (type(text)))\n",
        "  elif six.PY2:\n",
        "    if isinstance(text, str):\n",
        "      return text.decode(\"utf-8\", \"ignore\")\n",
        "    elif isinstance(text, unicode):\n",
        "      return text\n",
        "    else:\n",
        "      raise ValueError(\"Unsupported string type: %s\" % (type(text)))\n",
        "  else:\n",
        "    raise ValueError(\"Not running on Python2 or Python 3?\")\n",
        "\n",
        "\n",
        "def printable_text(text):\n",
        "  \"\"\"Returns text encoded in a way suitable for print or `tf.logging`.\"\"\"\n",
        "\n",
        "  # These functions want `str` for both Python2 and Python3, but in one case\n",
        "  # it's a Unicode string and in the other it's a byte string.\n",
        "  if six.PY3:\n",
        "    if isinstance(text, str):\n",
        "      return text\n",
        "    elif isinstance(text, bytes):\n",
        "      return text.decode(\"utf-8\", \"ignore\")\n",
        "    else:\n",
        "      raise ValueError(\"Unsupported string type: %s\" % (type(text)))\n",
        "  elif six.PY2:\n",
        "    if isinstance(text, str):\n",
        "      return text\n",
        "    elif isinstance(text, unicode):\n",
        "      return text.encode(\"utf-8\")\n",
        "    else:\n",
        "      raise ValueError(\"Unsupported string type: %s\" % (type(text)))\n",
        "  else:\n",
        "    raise ValueError(\"Not running on Python2 or Python 3?\")\n",
        "\n",
        "\n",
        "def load_vocab(vocab_file):\n",
        "  \"\"\"Loads a vocabulary file into a dictionary.\"\"\"\n",
        "  vocab = collections.OrderedDict()\n",
        "  index = 0\n",
        "  with tf.io.gfile.GFile(vocab_file, \"r\") as reader:\n",
        "    while True:\n",
        "      token = convert_to_unicode(reader.readline())\n",
        "      if not token:\n",
        "        break\n",
        "      token = token.strip()\n",
        "      vocab[token] = index\n",
        "      index += 1\n",
        "  return vocab\n",
        "\n",
        "\n",
        "def convert_by_vocab(vocab, items):\n",
        "  \"\"\"Converts a sequence of [tokens|ids] using the vocab.\"\"\"\n",
        "  output = []\n",
        "  for item in items:\n",
        "    output.append(vocab[item])\n",
        "  return output\n",
        "\n",
        "\n",
        "def convert_tokens_to_ids(vocab, tokens):\n",
        "  return convert_by_vocab(vocab, tokens)\n",
        "\n",
        "\n",
        "def convert_ids_to_tokens(inv_vocab, ids):\n",
        "  return convert_by_vocab(inv_vocab, ids)\n",
        "\n",
        "\n",
        "def whitespace_tokenize(text):\n",
        "  \"\"\"Runs basic whitespace cleaning and splitting on a piece of text.\"\"\"\n",
        "  text = text.strip()\n",
        "  if not text:\n",
        "    return []\n",
        "  tokens = text.split()\n",
        "  return tokens\n",
        "\n",
        "\n",
        "class FullTokenizer(object):\n",
        "  \"\"\"Runs end-to-end tokenziation.\"\"\"\n",
        "\n",
        "  def __init__(self, vocab_file, do_lower_case=True):\n",
        "    self.vocab = load_vocab(vocab_file)\n",
        "    self.inv_vocab = {v: k for k, v in self.vocab.items()}\n",
        "    self.basic_tokenizer = BasicTokenizer(do_lower_case=do_lower_case)\n",
        "    self.wordpiece_tokenizer = WordpieceTokenizer(vocab=self.vocab)\n",
        "\n",
        "  def tokenize(self, text):\n",
        "    split_tokens = []\n",
        "    for token in self.basic_tokenizer.tokenize(text):\n",
        "      for sub_token in self.wordpiece_tokenizer.tokenize(token):\n",
        "        split_tokens.append(sub_token)\n",
        "\n",
        "    return split_tokens\n",
        "\n",
        "  def convert_tokens_to_ids(self, tokens):\n",
        "    return convert_by_vocab(self.vocab, tokens)\n",
        "\n",
        "  def convert_ids_to_tokens(self, ids):\n",
        "    return convert_by_vocab(self.inv_vocab, ids)\n",
        "\n",
        "\n",
        "class BasicTokenizer(object):\n",
        "  \"\"\"Runs basic tokenization (punctuation splitting, lower casing, etc.).\"\"\"\n",
        "\n",
        "  def __init__(self, do_lower_case=True):\n",
        "    \"\"\"Constructs a BasicTokenizer.\n",
        "\n",
        "    Args:\n",
        "      do_lower_case: Whether to lower case the input.\n",
        "    \"\"\"\n",
        "    self.do_lower_case = do_lower_case\n",
        "\n",
        "  def tokenize(self, text):\n",
        "    \"\"\"Tokenizes a piece of text.\"\"\"\n",
        "    text = convert_to_unicode(text)\n",
        "    text = self._clean_text(text)\n",
        "\n",
        "    # This was added on November 1st, 2018 for the multilingual and Chinese\n",
        "    # models. This is also applied to the English models now, but it doesn't\n",
        "    # matter since the English models were not trained on any Chinese data\n",
        "    # and generally don't have any Chinese data in them (there are Chinese\n",
        "    # characters in the vocabulary because Wikipedia does have some Chinese\n",
        "    # words in the English Wikipedia.).\n",
        "    text = self._tokenize_chinese_chars(text)\n",
        "\n",
        "    orig_tokens = whitespace_tokenize(text)\n",
        "    split_tokens = []\n",
        "    for token in orig_tokens:\n",
        "      if self.do_lower_case:\n",
        "        token = token.lower()\n",
        "        token = self._run_strip_accents(token)\n",
        "      split_tokens.extend(self._run_split_on_punc(token))\n",
        "\n",
        "    output_tokens = whitespace_tokenize(\" \".join(split_tokens))\n",
        "    return output_tokens\n",
        "\n",
        "  def _run_strip_accents(self, text):\n",
        "    \"\"\"Strips accents from a piece of text.\"\"\"\n",
        "    text = unicodedata.normalize(\"NFD\", text)\n",
        "    output = []\n",
        "    for char in text:\n",
        "      cat = unicodedata.category(char)\n",
        "      if cat == \"Mn\":\n",
        "        continue\n",
        "      output.append(char)\n",
        "    return \"\".join(output)\n",
        "\n",
        "  def _run_split_on_punc(self, text):\n",
        "    \"\"\"Splits punctuation on a piece of text.\"\"\"\n",
        "    chars = list(text)\n",
        "    i = 0\n",
        "    start_new_word = True\n",
        "    output = []\n",
        "    while i < len(chars):\n",
        "      char = chars[i]\n",
        "      if _is_punctuation(char):\n",
        "        output.append([char])\n",
        "        start_new_word = True\n",
        "      else:\n",
        "        if start_new_word:\n",
        "          output.append([])\n",
        "        start_new_word = False\n",
        "        output[-1].append(char)\n",
        "      i += 1\n",
        "\n",
        "    return [\"\".join(x) for x in output]\n",
        "\n",
        "  def _tokenize_chinese_chars(self, text):\n",
        "    \"\"\"Adds whitespace around any CJK character.\"\"\"\n",
        "    output = []\n",
        "    for char in text:\n",
        "      cp = ord(char)\n",
        "      if self._is_chinese_char(cp):\n",
        "        output.append(\" \")\n",
        "        output.append(char)\n",
        "        output.append(\" \")\n",
        "      else:\n",
        "        output.append(char)\n",
        "    return \"\".join(output)\n",
        "\n",
        "  def _is_chinese_char(self, cp):\n",
        "    \"\"\"Checks whether CP is the codepoint of a CJK character.\"\"\"\n",
        "    # This defines a \"chinese character\" as anything in the CJK Unicode block:\n",
        "    #   https://en.wikipedia.org/wiki/CJK_Unified_Ideographs_(Unicode_block)\n",
        "    #\n",
        "    # Note that the CJK Unicode block is NOT all Japanese and Korean characters,\n",
        "    # despite its name. The modern Korean Hangul alphabet is a different block,\n",
        "    # as is Japanese Hiragana and Katakana. Those alphabets are used to write\n",
        "    # space-separated words, so they are not treated specially and handled\n",
        "    # like the all of the other languages.\n",
        "    if ((cp >= 0x4E00 and cp <= 0x9FFF) or  #\n",
        "        (cp >= 0x3400 and cp <= 0x4DBF) or  #\n",
        "        (cp >= 0x20000 and cp <= 0x2A6DF) or  #\n",
        "        (cp >= 0x2A700 and cp <= 0x2B73F) or  #\n",
        "        (cp >= 0x2B740 and cp <= 0x2B81F) or  #\n",
        "        (cp >= 0x2B820 and cp <= 0x2CEAF) or\n",
        "        (cp >= 0xF900 and cp <= 0xFAFF) or  #\n",
        "        (cp >= 0x2F800 and cp <= 0x2FA1F)):  #\n",
        "      return True\n",
        "\n",
        "    return False\n",
        "\n",
        "  def _clean_text(self, text):\n",
        "    \"\"\"Performs invalid character removal and whitespace cleanup on text.\"\"\"\n",
        "    output = []\n",
        "    for char in text:\n",
        "      cp = ord(char)\n",
        "      if cp == 0 or cp == 0xfffd or _is_control(char):\n",
        "        continue\n",
        "      if _is_whitespace(char):\n",
        "        output.append(\" \")\n",
        "      else:\n",
        "        output.append(char)\n",
        "    return \"\".join(output)\n",
        "\n",
        "\n",
        "class WordpieceTokenizer(object):\n",
        "  \"\"\"Runs WordPiece tokenziation.\"\"\"\n",
        "\n",
        "  def __init__(self, vocab, unk_token=\"[UNK]\", max_input_chars_per_word=200):\n",
        "    self.vocab = vocab\n",
        "    self.unk_token = unk_token\n",
        "    self.max_input_chars_per_word = max_input_chars_per_word\n",
        "\n",
        "  def tokenize(self, text):\n",
        "    \"\"\"Tokenizes a piece of text into its word pieces.\n",
        "\n",
        "    This uses a greedy longest-match-first algorithm to perform tokenization\n",
        "    using the given vocabulary.\n",
        "\n",
        "    For example:\n",
        "      input = \"unaffable\"\n",
        "      output = [\"un\", \"##aff\", \"##able\"]\n",
        "\n",
        "    Args:\n",
        "      text: A single token or whitespace separated tokens. This should have\n",
        "        already been passed through `BasicTokenizer.\n",
        "\n",
        "    Returns:\n",
        "      A list of wordpiece tokens.\n",
        "    \"\"\"\n",
        "\n",
        "    text = convert_to_unicode(text)\n",
        "\n",
        "    output_tokens = []\n",
        "    for token in whitespace_tokenize(text):\n",
        "      chars = list(token)\n",
        "      if len(chars) > self.max_input_chars_per_word:\n",
        "        output_tokens.append(self.unk_token)\n",
        "        continue\n",
        "\n",
        "      is_bad = False\n",
        "      start = 0\n",
        "      sub_tokens = []\n",
        "      while start < len(chars):\n",
        "        end = len(chars)\n",
        "        cur_substr = None\n",
        "        while start < end:\n",
        "          substr = \"\".join(chars[start:end])\n",
        "          if start > 0:\n",
        "            substr = \"##\" + substr\n",
        "          if substr in self.vocab:\n",
        "            cur_substr = substr\n",
        "            break\n",
        "          end -= 1\n",
        "        if cur_substr is None:\n",
        "          is_bad = True\n",
        "          break\n",
        "        sub_tokens.append(cur_substr)\n",
        "        start = end\n",
        "\n",
        "      if is_bad:\n",
        "        output_tokens.append(self.unk_token)\n",
        "      else:\n",
        "        output_tokens.extend(sub_tokens)\n",
        "    return output_tokens\n",
        "\n",
        "\n",
        "def _is_whitespace(char):\n",
        "  \"\"\"Checks whether `chars` is a whitespace character.\"\"\"\n",
        "  # \\t, \\n, and \\r are technically contorl characters but we treat them\n",
        "  # as whitespace since they are generally considered as such.\n",
        "  if char == \" \" or char == \"\\t\" or char == \"\\n\" or char == \"\\r\":\n",
        "    return True\n",
        "  cat = unicodedata.category(char)\n",
        "  if cat == \"Zs\":\n",
        "    return True\n",
        "  return False\n",
        "\n",
        "\n",
        "def _is_control(char):\n",
        "  \"\"\"Checks whether `chars` is a control character.\"\"\"\n",
        "  # These are technically control characters but we count them as whitespace\n",
        "  # characters.\n",
        "  if char == \"\\t\" or char == \"\\n\" or char == \"\\r\":\n",
        "    return False\n",
        "  cat = unicodedata.category(char)\n",
        "  if cat in (\"Cc\", \"Cf\"):\n",
        "    return True\n",
        "  return False\n",
        "\n",
        "\n",
        "def _is_punctuation(char):\n",
        "  \"\"\"Checks whether `chars` is a punctuation character.\"\"\"\n",
        "  cp = ord(char)\n",
        "  # We treat all non-letter/number ASCII as punctuation.\n",
        "  # Characters such as \"^\", \"$\", and \"`\" are not in the Unicode\n",
        "  # Punctuation class but we treat them as punctuation anyways, for\n",
        "  # consistency.\n",
        "  if ((cp >= 33 and cp <= 47) or (cp >= 58 and cp <= 64) or\n",
        "      (cp >= 91 and cp <= 96) or (cp >= 123 and cp <= 126)):\n",
        "    return True\n",
        "  cat = unicodedata.category(char)\n",
        "  if cat.startswith(\"P\"):\n",
        "    return True\n",
        "  return False"
      ],
      "metadata": {
        "id": "NoFZ220HHjtC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.run_functions_eagerly(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "GyqcAQttLGn4",
        "outputId": "befae314-07c6-435c-f012-ed3a54255715"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-f1ee9ce5753a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_functions_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/util/module_wrapper.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    191\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m       \u001b[0mattr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfmw_wrapped_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfmw_public_apis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow._api.v1.config' has no attribute 'run_functions_eagerly'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "module_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2'\n",
        "bert_layer = hub.KerasLayer(module_url, trainable=True)\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)"
      ],
      "metadata": {
        "id": "TVKbouXD9R1c"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "# nltk.download('stopwords')\n",
        "# nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9m2DUalP05p",
        "outputId": "9b913f2d-2323-4fd6-b8f7-b8d668e05fdb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DiP17LxyQhXm",
        "outputId": "a6f5c9bf-74cd-4c30-e3ba-426ee4953115"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a95db57a-9251-4c7b-8f92-b7c4bfb1f80e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article</th>\n",
              "      <th>category</th>\n",
              "      <th>label</th>\n",
              "      <th>data_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2108</th>\n",
              "      <td>broadband fuels online expression  fast web ac...</td>\n",
              "      <td>tech</td>\n",
              "      <td>4</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517</th>\n",
              "      <td>famed music director viotti dies  conductor ma...</td>\n",
              "      <td>entertainment</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>crisis 'ahead in social sciences'  a national ...</td>\n",
              "      <td>politics</td>\n",
              "      <td>2</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>626</th>\n",
              "      <td>sir paul rocks super bowl crowds  sir paul mcc...</td>\n",
              "      <td>entertainment</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>978</th>\n",
              "      <td>howard attacks cost of asylum  michael howard ...</td>\n",
              "      <td>politics</td>\n",
              "      <td>2</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a95db57a-9251-4c7b-8f92-b7c4bfb1f80e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a95db57a-9251-4c7b-8f92-b7c4bfb1f80e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a95db57a-9251-4c7b-8f92-b7c4bfb1f80e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                article  ... data_type\n",
              "2108  broadband fuels online expression  fast web ac...  ...     train\n",
              "517   famed music director viotti dies  conductor ma...  ...     train\n",
              "888   crisis 'ahead in social sciences'  a national ...  ...     train\n",
              "626   sir paul rocks super bowl crowds  sir paul mcc...  ...     train\n",
              "978   howard attacks cost of asylum  michael howard ...  ...     train\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['article']= train['article'].apply(nltk.word_tokenize)\n",
        "print('Tokenization complete.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMMuhj7OQNzg",
        "outputId": "49ab318c-a5f0-48d2-80c7-554a4f80bccb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenization complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "regex = '[a-z]+'\n",
        "a = [item for item in a if re.match(regex, item)]\n",
        "#a = a.apply(lambda x: [item for item in x if re.match(regex, item)])"
      ],
      "metadata": {
        "id": "W4bd48OZQD7o"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrbcqV3VUHBE",
        "outputId": "0f427b5a-e1c6-4c82-9401-1850f2e52fe4"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['broadband',\n",
              " 'fuels',\n",
              " 'online',\n",
              " 'expression',\n",
              " 'fast',\n",
              " 'web',\n",
              " 'access',\n",
              " 'is',\n",
              " 'encouraging',\n",
              " 'more',\n",
              " 'people',\n",
              " 'to',\n",
              " 'express',\n",
              " 'themselves',\n",
              " 'online',\n",
              " 'research',\n",
              " 'suggests',\n",
              " 'a',\n",
              " 'quarter',\n",
              " 'of',\n",
              " 'broadband',\n",
              " 'users',\n",
              " 'in',\n",
              " 'britain',\n",
              " 'regularly',\n",
              " 'up',\n",
              " '##load',\n",
              " 'content',\n",
              " 'and',\n",
              " 'have',\n",
              " 'personal',\n",
              " 'sites',\n",
              " 'according',\n",
              " 'to',\n",
              " 'a',\n",
              " 'report',\n",
              " 'by',\n",
              " 'uk',\n",
              " 'think',\n",
              " '-',\n",
              " 'tank',\n",
              " 'demos',\n",
              " 'it',\n",
              " 'said',\n",
              " 'that',\n",
              " 'having',\n",
              " 'an',\n",
              " 'always',\n",
              " '-',\n",
              " 'on',\n",
              " 'fast',\n",
              " 'connection',\n",
              " 'is',\n",
              " 'changing',\n",
              " 'the',\n",
              " 'way',\n",
              " 'people',\n",
              " 'use',\n",
              " 'the',\n",
              " 'internet',\n",
              " 'more',\n",
              " 'than',\n",
              " 'five',\n",
              " 'million',\n",
              " 'households',\n",
              " 'in',\n",
              " 'the',\n",
              " 'uk',\n",
              " 'have',\n",
              " 'broadband',\n",
              " 'and',\n",
              " 'that',\n",
              " 'number',\n",
              " 'is',\n",
              " 'growing',\n",
              " 'fast',\n",
              " 'the',\n",
              " 'demos',\n",
              " 'report',\n",
              " 'looked',\n",
              " 'at',\n",
              " 'the',\n",
              " 'impact',\n",
              " 'of',\n",
              " 'broadband',\n",
              " 'on',\n",
              " 'people',\n",
              " 'net',\n",
              " 'habits',\n",
              " 'it',\n",
              " 'found',\n",
              " 'that',\n",
              " 'more',\n",
              " 'than',\n",
              " 'half',\n",
              " 'of',\n",
              " 'those',\n",
              " 'with',\n",
              " 'broadband',\n",
              " 'logged',\n",
              " 'on',\n",
              " 'to',\n",
              " 'the',\n",
              " 'web',\n",
              " 'before',\n",
              " 'breakfast',\n",
              " 'one',\n",
              " 'in',\n",
              " 'five',\n",
              " 'even',\n",
              " 'admitted',\n",
              " 'to',\n",
              " 'getting',\n",
              " 'up',\n",
              " 'in',\n",
              " 'the',\n",
              " 'middle',\n",
              " 'of',\n",
              " 'the',\n",
              " 'night',\n",
              " 'to',\n",
              " 'brows',\n",
              " '##e',\n",
              " 'the',\n",
              " 'web',\n",
              " 'more',\n",
              " 'significantly',\n",
              " 'argues',\n",
              " 'the',\n",
              " 'report',\n",
              " 'broadband',\n",
              " 'is',\n",
              " 'encouraging',\n",
              " 'people',\n",
              " 'to',\n",
              " 'take',\n",
              " 'a',\n",
              " 'more',\n",
              " 'active',\n",
              " 'role',\n",
              " 'online',\n",
              " 'it',\n",
              " 'found',\n",
              " 'that',\n",
              " 'one',\n",
              " 'in',\n",
              " 'five',\n",
              " 'post',\n",
              " 'something',\n",
              " 'on',\n",
              " 'the',\n",
              " 'net',\n",
              " 'everyday',\n",
              " 'ranging',\n",
              " 'from',\n",
              " 'comments',\n",
              " 'or',\n",
              " 'opinions',\n",
              " 'on',\n",
              " 'sites',\n",
              " 'to',\n",
              " 'up',\n",
              " '##loading',\n",
              " 'photographs',\n",
              " 'broadband',\n",
              " 'is',\n",
              " 'putting',\n",
              " 'the',\n",
              " 'in',\n",
              " 'media',\n",
              " 'as',\n",
              " 'it',\n",
              " 'shifts',\n",
              " 'power',\n",
              " 'from',\n",
              " 'institutions',\n",
              " 'and',\n",
              " 'into',\n",
              " 'the',\n",
              " 'hands',\n",
              " 'of',\n",
              " 'the',\n",
              " 'individual',\n",
              " 'said',\n",
              " 'john',\n",
              " 'craig',\n",
              " 'co',\n",
              " '-',\n",
              " 'author',\n",
              " 'of',\n",
              " 'the',\n",
              " 'demos',\n",
              " 'report',\n",
              " 'from',\n",
              " 'self',\n",
              " '-',\n",
              " 'diagnosis',\n",
              " 'to',\n",
              " 'online',\n",
              " 'education',\n",
              " 'broadband',\n",
              " 'creates',\n",
              " 'social',\n",
              " 'innovation',\n",
              " 'that',\n",
              " 'moves',\n",
              " 'the',\n",
              " 'debate',\n",
              " 'beyond',\n",
              " 'simple',\n",
              " 'questions',\n",
              " 'of',\n",
              " 'access',\n",
              " 'and',\n",
              " 'speed',\n",
              " 'the',\n",
              " 'demos',\n",
              " 'report',\n",
              " 'entitled',\n",
              " 'broadband',\n",
              " 'britain',\n",
              " 'the',\n",
              " 'end',\n",
              " 'of',\n",
              " 'as',\n",
              " '##ym',\n",
              " '##metry',\n",
              " 'was',\n",
              " 'commissioned',\n",
              " 'by',\n",
              " 'net',\n",
              " 'provider',\n",
              " 'ao',\n",
              " '##l',\n",
              " 'broadband',\n",
              " 'is',\n",
              " 'moving',\n",
              " 'the',\n",
              " 'perception',\n",
              " 'of',\n",
              " 'the',\n",
              " 'internet',\n",
              " 'as',\n",
              " 'a',\n",
              " 'piece',\n",
              " 'of',\n",
              " 'technology',\n",
              " 'to',\n",
              " 'an',\n",
              " 'integral',\n",
              " 'part',\n",
              " 'of',\n",
              " 'home',\n",
              " 'life',\n",
              " 'in',\n",
              " 'the',\n",
              " 'uk',\n",
              " 'said',\n",
              " 'karen',\n",
              " 'thomson',\n",
              " 'chief',\n",
              " 'executive',\n",
              " 'of',\n",
              " 'ao',\n",
              " '##l',\n",
              " 'uk',\n",
              " 'with',\n",
              " 'many',\n",
              " 'people',\n",
              " 'spending',\n",
              " 'time',\n",
              " 'on',\n",
              " 'their',\n",
              " 'computers',\n",
              " 'as',\n",
              " 'automatically',\n",
              " 'as',\n",
              " 'they',\n",
              " 'might',\n",
              " 'switch',\n",
              " 'on',\n",
              " 'the',\n",
              " 'television',\n",
              " 'or',\n",
              " 'radio',\n",
              " 'according',\n",
              " 'to',\n",
              " 'analysts',\n",
              " 'nielsen',\n",
              " '/',\n",
              " '/',\n",
              " 'net',\n",
              " '##rating',\n",
              " '##s',\n",
              " 'more',\n",
              " 'than',\n",
              " 'of',\n",
              " 'the',\n",
              " 'million',\n",
              " 'uk',\n",
              " 'net',\n",
              " 'users',\n",
              " 'regularly',\n",
              " 'access',\n",
              " '##ing',\n",
              " 'the',\n",
              " 'web',\n",
              " 'from',\n",
              " 'home',\n",
              " 'each',\n",
              " 'month',\n",
              " 'are',\n",
              " 'logging',\n",
              " 'on',\n",
              " 'at',\n",
              " 'high',\n",
              " 'speed',\n",
              " 'they',\n",
              " 'spend',\n",
              " 'twice',\n",
              " 'as',\n",
              " 'long',\n",
              " 'online',\n",
              " 'than',\n",
              " 'people',\n",
              " 'on',\n",
              " 'dial',\n",
              " '-',\n",
              " 'up',\n",
              " 'connections',\n",
              " 'viewing',\n",
              " 'an',\n",
              " 'average',\n",
              " 'of',\n",
              " 'pages',\n",
              " 'per',\n",
              " 'month',\n",
              " 'the',\n",
              " 'popularity',\n",
              " 'of',\n",
              " 'fast',\n",
              " 'net',\n",
              " 'access',\n",
              " 'is',\n",
              " 'growing',\n",
              " 'partly',\n",
              " 'fuel',\n",
              " '##led',\n",
              " 'by',\n",
              " 'fierce',\n",
              " 'competition',\n",
              " 'over',\n",
              " 'prices',\n",
              " 'and',\n",
              " 'services']"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JiQ4Wm5tL26b",
        "outputId": "cd412cdc-0ccf-4d98-c006-9bf8c52c048c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8c91bf04-e0ad-4b03-9270-72f18d829408\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article</th>\n",
              "      <th>category</th>\n",
              "      <th>label</th>\n",
              "      <th>data_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2108</th>\n",
              "      <td>broadband fuels online expression  fast web ac...</td>\n",
              "      <td>tech</td>\n",
              "      <td>4</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517</th>\n",
              "      <td>famed music director viotti dies  conductor ma...</td>\n",
              "      <td>entertainment</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>crisis 'ahead in social sciences'  a national ...</td>\n",
              "      <td>politics</td>\n",
              "      <td>2</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>626</th>\n",
              "      <td>sir paul rocks super bowl crowds  sir paul mcc...</td>\n",
              "      <td>entertainment</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>978</th>\n",
              "      <td>howard attacks cost of asylum  michael howard ...</td>\n",
              "      <td>politics</td>\n",
              "      <td>2</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c91bf04-e0ad-4b03-9270-72f18d829408')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8c91bf04-e0ad-4b03-9270-72f18d829408 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8c91bf04-e0ad-4b03-9270-72f18d829408');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                article  ... data_type\n",
              "2108  broadband fuels online expression  fast web ac...  ...     train\n",
              "517   famed music director viotti dies  conductor ma...  ...     train\n",
              "888   crisis 'ahead in social sciences'  a national ...  ...     train\n",
              "626   sir paul rocks super bowl crowds  sir paul mcc...  ...     train\n",
              "978   howard attacks cost of asylum  michael howard ...  ...     train\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#function defined to encode the text data to a format which the bert model can understand\n",
        "all_word_ids = []\n",
        "all_masks = []\n",
        "all_type_ids = []\n",
        "\n",
        "def bert_encode(texts, max_len):\n",
        "\n",
        "  for text in texts:\n",
        "      text = tokenizer.tokenize(text)\n",
        "\n",
        "          \n",
        "      text = text[:max_len-2]\n",
        "      input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
        "      pad_len = max_len - len(input_sequence)\n",
        "      \n",
        "      tokens = tokenizer.convert_tokens_to_ids(input_sequence) + [0] * pad_len\n",
        "      pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
        "      segment_ids = [0] * max_len\n",
        "      \n",
        "      all_word_ids.append(tokens)\n",
        "      all_masks.append(pad_masks)\n",
        "      all_type_ids.append(segment_ids)\n",
        "  \n",
        "  return np.array(all_word_ids), np.array(all_masks), np.array(all_type_ids)"
      ],
      "metadata": {
        "id": "C1AYyuWqQoZn"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function defined to encode the text data to a format which the bert model can understand\n",
        "all_word_ids = []\n",
        "all_masks = []\n",
        "all_type_ids = []\n",
        "def bert_encode1(texts, tokenizer, max_len):\n",
        "\n",
        "  for text in texts:\n",
        "      text = tokenizer.tokenize(text)\n",
        "\n",
        "          \n",
        "      text = text[:max_len-2]\n",
        "      input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
        "      pad_len = max_len - len(input_sequence)\n",
        "      \n",
        "      tokens = tokenizer.convert_tokens_to_ids(input_sequence) + [0] * pad_len\n",
        "      pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
        "      segment_ids = [0] * max_len\n",
        "      \n",
        "      all_word_ids.append(tokens)\n",
        "      all_masks.append(pad_masks)\n",
        "      all_type_ids.append(segment_ids)\n",
        "  \n",
        "  return np.array(all_word_ids), np.array(all_masks), np.array(all_type_ids)"
      ],
      "metadata": {
        "id": "pjq7tX7h-ORZ"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_word_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXFuvVy5QECX",
        "outputId": "546f0501-d687-4f2a-e39c-c610a2eacd56"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sa = ' '.join(map(str, train.article.values[0]))"
      ],
      "metadata": {
        "id": "nfioc2klNUKY"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.article.values[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "QSpZ-W5kNquq",
        "outputId": "d10f876f-5bf3-4645-9e5f-c80a7958e4bd"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'broadband fuels online expression  fast web access is encouraging more people to express themselves online, research suggests.  a quarter of broadband users in britain regularly upload content and have personal sites, according to a report by uk think-tank demos. it said that having an always-on, fast connection is changing the way people use the internet. more than five million households in the uk have broadband and that number is growing fast.  the demos report looked at the impact of broadband on people\\'s net habits. it found that more than half of those with broadband logged on to the web before breakfast. one in five even admitted to getting up in the middle of the night to browse the web.  more significantly, argues the report, broadband is encouraging people to take a more active role online. it found that one in five post something on the net everyday, ranging from comments or opinions on sites to uploading photographs. \"broadband is putting the \\'me\\' in media as it shifts power from institutions and into the hands of the individual,\" said john craig, co-author of the demos report. \"from self-diagnosis to online education, broadband creates social innovation that moves the debate beyond simple questions of access and speed.\" the demos report, entitled broadband britain: the end of asymmetry?, was commissioned by net provider aol. \"broadband is moving the perception of the internet as a piece of technology to an integral part of home life in the uk,\" said karen thomson, chief executive of aol uk, \"with many people spending time on their computers as automatically as they might switch on the television or radio.\" according to analysts nielsen//netratings, more than 50% of the 22.8 million uk net users regularly accessing the web from home each month are logging on at high speed they spend twice as long online than people on dial-up connections, viewing an average of 1,444 pages per month. the popularity of fast net access is growing, partly fuelled by fierce competition over prices and services. '"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "Px640c8FNe24",
        "outputId": "ba4501a4-b226-4423-8c7e-acd7b4f843e3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'broadband fuels online expression fast web access is encouraging more people to express themselves online research suggests a quarter of broadband users in britain regularly upload content and have personal sites according to a report by uk think-tank demos it said that having an always-on fast connection is changing the way people use the internet more than five million households in the uk have broadband and that number is growing fast the demos report looked at the impact of broadband on people net habits it found that more than half of those with broadband logged on to the web before breakfast one in five even admitted to getting up in the middle of the night to browse the web more significantly argues the report broadband is encouraging people to take a more active role online it found that one in five post something on the net everyday ranging from comments or opinions on sites to uploading photographs broadband is putting the in media as it shifts power from institutions and into the hands of the individual said john craig co-author of the demos report from self-diagnosis to online education broadband creates social innovation that moves the debate beyond simple questions of access and speed the demos report entitled broadband britain the end of asymmetry was commissioned by net provider aol broadband is moving the perception of the internet as a piece of technology to an integral part of home life in the uk said karen thomson chief executive of aol uk with many people spending time on their computers as automatically as they might switch on the television or radio according to analysts nielsen//netratings more than of the million uk net users regularly accessing the web from home each month are logging on at high speed they spend twice as long online than people on dial-up connections viewing an average of pages per month the popularity of fast net access is growing partly fuelled by fierce competition over prices and services'"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Here is what the tokenised sample of the first training set observation looks like\n",
        "print(tokenizer.tokenize(sa))"
      ],
      "metadata": {
        "id": "Hc77tpQoQAGu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2bbda1a-0f25-429a-f541-4123998fc594"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['broadband', 'fuels', 'online', 'expression', 'fast', 'web', 'access', 'is', 'encouraging', 'more', 'people', 'to', 'express', 'themselves', 'online', 'research', 'suggests', 'a', 'quarter', 'of', 'broadband', 'users', 'in', 'britain', 'regularly', 'up', '##load', 'content', 'and', 'have', 'personal', 'sites', 'according', 'to', 'a', 'report', 'by', 'uk', 'think', '-', 'tank', 'demos', 'it', 'said', 'that', 'having', 'an', 'always', '-', 'on', 'fast', 'connection', 'is', 'changing', 'the', 'way', 'people', 'use', 'the', 'internet', 'more', 'than', 'five', 'million', 'households', 'in', 'the', 'uk', 'have', 'broadband', 'and', 'that', 'number', 'is', 'growing', 'fast', 'the', 'demos', 'report', 'looked', 'at', 'the', 'impact', 'of', 'broadband', 'on', 'people', 'net', 'habits', 'it', 'found', 'that', 'more', 'than', 'half', 'of', 'those', 'with', 'broadband', 'logged', 'on', 'to', 'the', 'web', 'before', 'breakfast', 'one', 'in', 'five', 'even', 'admitted', 'to', 'getting', 'up', 'in', 'the', 'middle', 'of', 'the', 'night', 'to', 'brows', '##e', 'the', 'web', 'more', 'significantly', 'argues', 'the', 'report', 'broadband', 'is', 'encouraging', 'people', 'to', 'take', 'a', 'more', 'active', 'role', 'online', 'it', 'found', 'that', 'one', 'in', 'five', 'post', 'something', 'on', 'the', 'net', 'everyday', 'ranging', 'from', 'comments', 'or', 'opinions', 'on', 'sites', 'to', 'up', '##loading', 'photographs', 'broadband', 'is', 'putting', 'the', 'in', 'media', 'as', 'it', 'shifts', 'power', 'from', 'institutions', 'and', 'into', 'the', 'hands', 'of', 'the', 'individual', 'said', 'john', 'craig', 'co', '-', 'author', 'of', 'the', 'demos', 'report', 'from', 'self', '-', 'diagnosis', 'to', 'online', 'education', 'broadband', 'creates', 'social', 'innovation', 'that', 'moves', 'the', 'debate', 'beyond', 'simple', 'questions', 'of', 'access', 'and', 'speed', 'the', 'demos', 'report', 'entitled', 'broadband', 'britain', 'the', 'end', 'of', 'as', '##ym', '##metry', 'was', 'commissioned', 'by', 'net', 'provider', 'ao', '##l', 'broadband', 'is', 'moving', 'the', 'perception', 'of', 'the', 'internet', 'as', 'a', 'piece', 'of', 'technology', 'to', 'an', 'integral', 'part', 'of', 'home', 'life', 'in', 'the', 'uk', 'said', 'karen', 'thomson', 'chief', 'executive', 'of', 'ao', '##l', 'uk', 'with', 'many', 'people', 'spending', 'time', 'on', 'their', 'computers', 'as', 'automatically', 'as', 'they', 'might', 'switch', 'on', 'the', 'television', 'or', 'radio', 'according', 'to', 'analysts', 'nielsen', '/', '/', 'net', '##rating', '##s', 'more', 'than', 'of', 'the', 'million', 'uk', 'net', 'users', 'regularly', 'access', '##ing', 'the', 'web', 'from', 'home', 'each', 'month', 'are', 'logging', 'on', 'at', 'high', 'speed', 'they', 'spend', 'twice', 'as', 'long', 'online', 'than', 'people', 'on', 'dial', '-', 'up', 'connections', 'viewing', 'an', 'average', 'of', 'pages', 'per', 'month', 'the', 'popularity', 'of', 'fast', 'net', 'access', 'is', 'growing', 'partly', 'fuel', '##led', 'by', 'fierce', 'competition', 'over', 'prices', 'and', 'services']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now format the text in to input features which the BERT model expects."
      ],
      "metadata": {
        "id": "F-qoKat3mxOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = train[:2]"
      ],
      "metadata": {
        "id": "oVvPzVIlMD_B"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "Q73T-WvGMH1V",
        "outputId": "12241cce-8094-4be0-f49b-bed3c60a9087"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-19da747e-77a6-4419-9b47-f29b5e2637c0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article</th>\n",
              "      <th>category</th>\n",
              "      <th>label</th>\n",
              "      <th>data_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2108</th>\n",
              "      <td>[broadband, fuels, online, expression, fast, w...</td>\n",
              "      <td>tech</td>\n",
              "      <td>4</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517</th>\n",
              "      <td>[famed, music, director, viotti, dies, conduct...</td>\n",
              "      <td>entertainment</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-19da747e-77a6-4419-9b47-f29b5e2637c0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-19da747e-77a6-4419-9b47-f29b5e2637c0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-19da747e-77a6-4419-9b47-f29b5e2637c0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                article  ... data_type\n",
              "2108  [broadband, fuels, online, expression, fast, w...  ...     train\n",
              "517   [famed, music, director, viotti, dies, conduct...  ...     train\n",
              "\n",
              "[2 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We'll set sequences to be at most 150 tokens long.\n",
        "max_len = 512\n",
        "train_input = bert_encode1(train.article.values,tokenizer, max_len=max_len)\n",
        "#test_input = bert_encode(test.article.values, tokenizer, max_len=max_len)"
      ],
      "metadata": {
        "id": "NV_qUYoL_AoM"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_input[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MV_gyUi0_DnN",
        "outputId": "16cf575e-2e59-493e-9c5a-efa837f6f8d9"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  101, 19595, 20145, ...,     0,     0,     0],\n",
              "       [  101, 15607,  2189, ...,     0,     0,     0],\n",
              "       [  101,  5325,  1005, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [  101, 10503,  1005, ...,     0,     0,     0],\n",
              "       [  101,  9433,  2083, ...,  4771,  9433,   102],\n",
              "       [  101, 12616,  1005, ...,  1999,  6251,   102]])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Doing 1 hot encoding to our label column ie it will create an array of 5 (since we have 5 classes) and put 1 under the category for each row\n",
        "\n",
        "#try this also - 1 hot from tensorflow - \n",
        "#one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "train_labels = tf.keras.utils.to_categorical(train.label.values, num_classes=5)\n",
        "train_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tymIKHsA9dTu",
        "outputId": "c6f337a5-12d5-4bfe-d71e-640cb54d67cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 1.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = train.article.values[0]\n",
        "b = tokenizer.tokenize(sa)"
      ],
      "metadata": {
        "id": "cP_LnkI4OkcN"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Example on first observation in the training set\n",
        "\n",
        "\n",
        "print(\"Sentence : \", train.article.values[0])\n",
        "print(\"-\"*30)\n",
        "print(\"Tokens : \", tokenizer.tokenize(train.article.values[0]))\n",
        "print(\"-\"*30)\n",
        "print(\"Word IDs : \", all_word_ids[0])\n",
        "print(\"-\"*30)\n",
        "print(\"Input Masks : \", all_masks[0])\n",
        "print(\"-\"*30)\n",
        "print(\"Type IDs : \", all_type_ids[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5reKEoEw_Lx-",
        "outputId": "e1afc634-9f0a-44b1-e6b9-c1a79d7a950a"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence :  broadband fuels online expression  fast web access is encouraging more people to express themselves online, research suggests.  a quarter of broadband users in britain regularly upload content and have personal sites, according to a report by uk think-tank demos. it said that having an always-on, fast connection is changing the way people use the internet. more than five million households in the uk have broadband and that number is growing fast.  the demos report looked at the impact of broadband on people's net habits. it found that more than half of those with broadband logged on to the web before breakfast. one in five even admitted to getting up in the middle of the night to browse the web.  more significantly, argues the report, broadband is encouraging people to take a more active role online. it found that one in five post something on the net everyday, ranging from comments or opinions on sites to uploading photographs. \"broadband is putting the 'me' in media as it shifts power from institutions and into the hands of the individual,\" said john craig, co-author of the demos report. \"from self-diagnosis to online education, broadband creates social innovation that moves the debate beyond simple questions of access and speed.\" the demos report, entitled broadband britain: the end of asymmetry?, was commissioned by net provider aol. \"broadband is moving the perception of the internet as a piece of technology to an integral part of home life in the uk,\" said karen thomson, chief executive of aol uk, \"with many people spending time on their computers as automatically as they might switch on the television or radio.\" according to analysts nielsen//netratings, more than 50% of the 22.8 million uk net users regularly accessing the web from home each month are logging on at high speed they spend twice as long online than people on dial-up connections, viewing an average of 1,444 pages per month. the popularity of fast net access is growing, partly fuelled by fierce competition over prices and services. \n",
            "------------------------------\n",
            "Tokens :  ['broadband', 'fuels', 'online', 'expression', 'fast', 'web', 'access', 'is', 'encouraging', 'more', 'people', 'to', 'express', 'themselves', 'online', ',', 'research', 'suggests', '.', 'a', 'quarter', 'of', 'broadband', 'users', 'in', 'britain', 'regularly', 'up', '##load', 'content', 'and', 'have', 'personal', 'sites', ',', 'according', 'to', 'a', 'report', 'by', 'uk', 'think', '-', 'tank', 'demos', '.', 'it', 'said', 'that', 'having', 'an', 'always', '-', 'on', ',', 'fast', 'connection', 'is', 'changing', 'the', 'way', 'people', 'use', 'the', 'internet', '.', 'more', 'than', 'five', 'million', 'households', 'in', 'the', 'uk', 'have', 'broadband', 'and', 'that', 'number', 'is', 'growing', 'fast', '.', 'the', 'demos', 'report', 'looked', 'at', 'the', 'impact', 'of', 'broadband', 'on', 'people', \"'\", 's', 'net', 'habits', '.', 'it', 'found', 'that', 'more', 'than', 'half', 'of', 'those', 'with', 'broadband', 'logged', 'on', 'to', 'the', 'web', 'before', 'breakfast', '.', 'one', 'in', 'five', 'even', 'admitted', 'to', 'getting', 'up', 'in', 'the', 'middle', 'of', 'the', 'night', 'to', 'brows', '##e', 'the', 'web', '.', 'more', 'significantly', ',', 'argues', 'the', 'report', ',', 'broadband', 'is', 'encouraging', 'people', 'to', 'take', 'a', 'more', 'active', 'role', 'online', '.', 'it', 'found', 'that', 'one', 'in', 'five', 'post', 'something', 'on', 'the', 'net', 'everyday', ',', 'ranging', 'from', 'comments', 'or', 'opinions', 'on', 'sites', 'to', 'up', '##loading', 'photographs', '.', '\"', 'broadband', 'is', 'putting', 'the', \"'\", 'me', \"'\", 'in', 'media', 'as', 'it', 'shifts', 'power', 'from', 'institutions', 'and', 'into', 'the', 'hands', 'of', 'the', 'individual', ',', '\"', 'said', 'john', 'craig', ',', 'co', '-', 'author', 'of', 'the', 'demos', 'report', '.', '\"', 'from', 'self', '-', 'diagnosis', 'to', 'online', 'education', ',', 'broadband', 'creates', 'social', 'innovation', 'that', 'moves', 'the', 'debate', 'beyond', 'simple', 'questions', 'of', 'access', 'and', 'speed', '.', '\"', 'the', 'demos', 'report', ',', 'entitled', 'broadband', 'britain', ':', 'the', 'end', 'of', 'as', '##ym', '##metry', '?', ',', 'was', 'commissioned', 'by', 'net', 'provider', 'ao', '##l', '.', '\"', 'broadband', 'is', 'moving', 'the', 'perception', 'of', 'the', 'internet', 'as', 'a', 'piece', 'of', 'technology', 'to', 'an', 'integral', 'part', 'of', 'home', 'life', 'in', 'the', 'uk', ',', '\"', 'said', 'karen', 'thomson', ',', 'chief', 'executive', 'of', 'ao', '##l', 'uk', ',', '\"', 'with', 'many', 'people', 'spending', 'time', 'on', 'their', 'computers', 'as', 'automatically', 'as', 'they', 'might', 'switch', 'on', 'the', 'television', 'or', 'radio', '.', '\"', 'according', 'to', 'analysts', 'nielsen', '/', '/', 'net', '##rating', '##s', ',', 'more', 'than', '50', '%', 'of', 'the', '22', '.', '8', 'million', 'uk', 'net', 'users', 'regularly', 'access', '##ing', 'the', 'web', 'from', 'home', 'each', 'month', 'are', 'logging', 'on', 'at', 'high', 'speed', 'they', 'spend', 'twice', 'as', 'long', 'online', 'than', 'people', 'on', 'dial', '-', 'up', 'connections', ',', 'viewing', 'an', 'average', 'of', '1', ',', '44', '##4', 'pages', 'per', 'month', '.', 'the', 'popularity', 'of', 'fast', 'net', 'access', 'is', 'growing', ',', 'partly', 'fuel', '##led', 'by', 'fierce', 'competition', 'over', 'prices', 'and', 'services', '.']\n",
            "------------------------------\n",
            "Word IDs :  [101, 19595, 20145, 3784, 3670, 3435, 4773, 3229, 2003, 11434, 2062, 2111, 2000, 4671, 3209, 3784, 1010, 2470, 6083, 1012, 1037, 4284, 1997, 19595, 5198, 1999, 3725, 5570, 2039, 11066, 4180, 1998, 2031, 3167, 4573, 1010, 2429, 2000, 1037, 3189, 2011, 2866, 2228, 1011, 4951, 18267, 1012, 2009, 2056, 2008, 2383, 2019, 2467, 1011, 2006, 1010, 3435, 4434, 2003, 5278, 1996, 2126, 2111, 2224, 1996, 4274, 1012, 2062, 2084, 2274, 2454, 3911, 1999, 1996, 2866, 2031, 19595, 1998, 2008, 2193, 2003, 3652, 3435, 1012, 1996, 18267, 3189, 2246, 2012, 1996, 4254, 1997, 19595, 2006, 2111, 1005, 1055, 5658, 14243, 1012, 2009, 2179, 2008, 2062, 2084, 2431, 1997, 2216, 2007, 19595, 26618, 2006, 2000, 1996, 4773, 2077, 6350, 1012, 2028, 1999, 2274, 2130, 4914, 2000, 2893, 2039, 1999, 1996, 2690, 1997, 1996, 2305, 2000, 11347, 2063, 1996, 4773, 1012, 2062, 6022, 1010, 9251, 1996, 3189, 1010, 19595, 2003, 11434, 2111, 2000, 2202, 1037, 2062, 3161, 2535, 3784, 1012, 2009, 2179, 2008, 2028, 1999, 2274, 2695, 2242, 2006, 1996, 5658, 10126, 1010, 7478, 2013, 7928, 2030, 10740, 2006, 4573, 2000, 2039, 18570, 7008, 1012, 1000, 19595, 2003, 5128, 1996, 1005, 2033, 1005, 1999, 2865, 2004, 2009, 12363, 2373, 2013, 4896, 1998, 2046, 1996, 2398, 1997, 1996, 3265, 1010, 1000, 2056, 2198, 7010, 1010, 2522, 1011, 3166, 1997, 1996, 18267, 3189, 1012, 1000, 2013, 2969, 1011, 11616, 2000, 3784, 2495, 1010, 19595, 9005, 2591, 8144, 2008, 5829, 1996, 5981, 3458, 3722, 3980, 1997, 3229, 1998, 3177, 1012, 1000, 1996, 18267, 3189, 1010, 4709, 19595, 3725, 1024, 1996, 2203, 1997, 2004, 24335, 24327, 1029, 1010, 2001, 4837, 2011, 5658, 10802, 20118, 2140, 1012, 1000, 19595, 2003, 3048, 1996, 10617, 1997, 1996, 4274, 2004, 1037, 3538, 1997, 2974, 2000, 2019, 9897, 2112, 1997, 2188, 2166, 1999, 1996, 2866, 1010, 1000, 2056, 8129, 11161, 1010, 2708, 3237, 1997, 20118, 2140, 2866, 1010, 1000, 2007, 2116, 2111, 5938, 2051, 2006, 2037, 7588, 2004, 8073, 2004, 2027, 2453, 6942, 2006, 1996, 2547, 2030, 2557, 1012, 1000, 2429, 2000, 18288, 13188, 1013, 1013, 5658, 15172, 2015, 1010, 2062, 2084, 2753, 1003, 1997, 1996, 2570, 1012, 1022, 2454, 2866, 5658, 5198, 5570, 3229, 2075, 1996, 4773, 2013, 2188, 2169, 3204, 2024, 15899, 2006, 2012, 2152, 3177, 2027, 5247, 3807, 2004, 2146, 3784, 2084, 2111, 2006, 13764, 1011, 2039, 7264, 1010, 10523, 2019, 2779, 1997, 1015, 1010, 4008, 2549, 5530, 2566, 3204, 1012, 1996, 6217, 1997, 3435, 5658, 3229, 2003, 3652, 1010, 6576, 4762, 3709, 2011, 9205, 2971, 2058, 7597, 1998, 2578, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "------------------------------\n",
            "Input Masks :  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "------------------------------\n",
            "Type IDs :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_word_ids[0]"
      ],
      "metadata": {
        "id": "VcqAoZePQXyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#############take this screenshote"
      ],
      "metadata": {
        "id": "WcuLnXFFRHm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "#print(\"Sentence : \", a)\n",
        "#print(\"-\"*30)\n",
        "print(\"Tokens : \", a)\n",
        "print(\"-\"*30)\n",
        "print(\"Word IDs : \", all_word_ids[0])\n",
        "print(\"-\"*30)\n",
        "print(\"Input Masks : \", all_masks[0])\n",
        "print(\"-\"*30)\n",
        "print(\"Type IDs : \", all_type_ids[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cF55PxIEPSL5",
        "outputId": "469034bf-2749-4cd3-fb03-1247424f0774"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens :  ['broadband', 'fuels', 'online', 'expression', 'fast', 'web', 'access', 'is', 'encouraging', 'more', 'people', 'to', 'express', 'themselves', 'online', 'research', 'suggests', 'a', 'quarter', 'of', 'broadband', 'users', 'in', 'britain', 'regularly', 'upload', 'content', 'and', 'have', 'personal', 'sites', 'according', 'to', 'a', 'report', 'by', 'uk', 'think-tank', 'demos', 'it', 'said', 'that', 'having', 'an', 'always-on', 'fast', 'connection', 'is', 'changing', 'the', 'way', 'people', 'use', 'the', 'internet', 'more', 'than', 'five', 'million', 'households', 'in', 'the', 'uk', 'have', 'broadband', 'and', 'that', 'number', 'is', 'growing', 'fast', 'the', 'demos', 'report', 'looked', 'at', 'the', 'impact', 'of', 'broadband', 'on', 'people', 'net', 'habits', 'it', 'found', 'that', 'more', 'than', 'half', 'of', 'those', 'with', 'broadband', 'logged', 'on', 'to', 'the', 'web', 'before', 'breakfast', 'one', 'in', 'five', 'even', 'admitted', 'to', 'getting', 'up', 'in', 'the', 'middle', 'of', 'the', 'night', 'to', 'browse', 'the', 'web', 'more', 'significantly', 'argues', 'the', 'report', 'broadband', 'is', 'encouraging', 'people', 'to', 'take', 'a', 'more', 'active', 'role', 'online', 'it', 'found', 'that', 'one', 'in', 'five', 'post', 'something', 'on', 'the', 'net', 'everyday', 'ranging', 'from', 'comments', 'or', 'opinions', 'on', 'sites', 'to', 'uploading', 'photographs', 'broadband', 'is', 'putting', 'the', 'in', 'media', 'as', 'it', 'shifts', 'power', 'from', 'institutions', 'and', 'into', 'the', 'hands', 'of', 'the', 'individual', 'said', 'john', 'craig', 'co-author', 'of', 'the', 'demos', 'report', 'from', 'self-diagnosis', 'to', 'online', 'education', 'broadband', 'creates', 'social', 'innovation', 'that', 'moves', 'the', 'debate', 'beyond', 'simple', 'questions', 'of', 'access', 'and', 'speed', 'the', 'demos', 'report', 'entitled', 'broadband', 'britain', 'the', 'end', 'of', 'asymmetry', 'was', 'commissioned', 'by', 'net', 'provider', 'aol', 'broadband', 'is', 'moving', 'the', 'perception', 'of', 'the', 'internet', 'as', 'a', 'piece', 'of', 'technology', 'to', 'an', 'integral', 'part', 'of', 'home', 'life', 'in', 'the', 'uk', 'said', 'karen', 'thomson', 'chief', 'executive', 'of', 'aol', 'uk', 'with', 'many', 'people', 'spending', 'time', 'on', 'their', 'computers', 'as', 'automatically', 'as', 'they', 'might', 'switch', 'on', 'the', 'television', 'or', 'radio', 'according', 'to', 'analysts', 'nielsen//netratings', 'more', 'than', 'of', 'the', 'million', 'uk', 'net', 'users', 'regularly', 'accessing', 'the', 'web', 'from', 'home', 'each', 'month', 'are', 'logging', 'on', 'at', 'high', 'speed', 'they', 'spend', 'twice', 'as', 'long', 'online', 'than', 'people', 'on', 'dial-up', 'connections', 'viewing', 'an', 'average', 'of', 'pages', 'per', 'month', 'the', 'popularity', 'of', 'fast', 'net', 'access', 'is', 'growing', 'partly', 'fuelled', 'by', 'fierce', 'competition', 'over', 'prices', 'and', 'services']\n",
            "------------------------------\n",
            "Word IDs :  [101, 19595, 20145, 3784, 3670, 3435, 4773, 3229, 2003, 11434, 2062, 2111, 2000, 4671, 3209, 3784, 1010, 2470, 6083, 1012, 1037, 4284, 1997, 19595, 5198, 1999, 3725, 5570, 2039, 11066, 4180, 1998, 2031, 3167, 4573, 1010, 2429, 2000, 1037, 3189, 2011, 2866, 2228, 1011, 4951, 18267, 1012, 2009, 2056, 2008, 2383, 2019, 2467, 1011, 2006, 1010, 3435, 4434, 2003, 5278, 1996, 2126, 2111, 2224, 1996, 4274, 1012, 2062, 2084, 2274, 2454, 3911, 1999, 1996, 2866, 2031, 19595, 1998, 2008, 2193, 2003, 3652, 3435, 1012, 1996, 18267, 3189, 2246, 2012, 1996, 4254, 1997, 19595, 2006, 2111, 1005, 1055, 5658, 14243, 1012, 2009, 2179, 2008, 2062, 2084, 2431, 1997, 2216, 2007, 19595, 26618, 2006, 2000, 1996, 4773, 2077, 6350, 1012, 2028, 1999, 2274, 2130, 4914, 2000, 2893, 2039, 1999, 1996, 2690, 1997, 1996, 2305, 2000, 11347, 2063, 1996, 4773, 1012, 2062, 6022, 1010, 9251, 1996, 3189, 1010, 19595, 2003, 11434, 2111, 2000, 2202, 1037, 2062, 3161, 2535, 3784, 1012, 2009, 2179, 2008, 2028, 1999, 2274, 2695, 2242, 2006, 1996, 5658, 10126, 1010, 7478, 2013, 7928, 2030, 10740, 2006, 4573, 2000, 2039, 18570, 7008, 1012, 1000, 19595, 2003, 5128, 1996, 1005, 2033, 1005, 1999, 2865, 2004, 2009, 12363, 2373, 2013, 4896, 1998, 2046, 1996, 2398, 1997, 1996, 3265, 1010, 1000, 2056, 2198, 7010, 1010, 2522, 1011, 3166, 1997, 1996, 18267, 3189, 1012, 1000, 2013, 2969, 1011, 11616, 2000, 3784, 2495, 1010, 19595, 9005, 2591, 8144, 2008, 5829, 1996, 5981, 3458, 3722, 3980, 1997, 3229, 1998, 3177, 1012, 1000, 1996, 18267, 3189, 1010, 4709, 19595, 3725, 1024, 1996, 2203, 1997, 2004, 24335, 24327, 1029, 1010, 2001, 4837, 2011, 5658, 10802, 20118, 2140, 1012, 1000, 19595, 2003, 3048, 1996, 10617, 1997, 1996, 4274, 2004, 1037, 3538, 1997, 2974, 2000, 2019, 9897, 2112, 1997, 2188, 2166, 1999, 1996, 2866, 1010, 1000, 2056, 8129, 11161, 1010, 2708, 3237, 1997, 20118, 2140, 2866, 1010, 1000, 2007, 2116, 2111, 5938, 2051, 2006, 2037, 7588, 2004, 8073, 2004, 2027, 2453, 6942, 2006, 1996, 2547, 2030, 2557, 1012, 1000, 2429, 2000, 18288, 13188, 1013, 1013, 5658, 15172, 2015, 1010, 2062, 2084, 2753, 1003, 1997, 1996, 2570, 1012, 1022, 2454, 2866, 5658, 5198, 5570, 3229, 2075, 1996, 4773, 2013, 2188, 2169, 3204, 2024, 15899, 2006, 2012, 2152, 3177, 2027, 5247, 3807, 2004, 2146, 3784, 2084, 2111, 2006, 13764, 1011, 2039, 7264, 1010, 10523, 2019, 2779, 1997, 1015, 1010, 4008, 2549, 5530, 2566, 3204, 1012, 1996, 6217, 1997, 3435, 5658, 3229, 2003, 3652, 1010, 6576, 4762, 3709, 2011, 9205, 2971, 2058, 7597, 1998, 2578, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "------------------------------\n",
            "Input Masks :  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "------------------------------\n",
            "Type IDs :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import logging\n",
        "logging.basicConfig(level=logging.INFO)"
      ],
      "metadata": {
        "id": "IOYPvHgy54ZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now building A Multi-Class Classifier Model using BERT (BERT layer already imported)"
      ],
      "metadata": {
        "id": "Y19SNRXYnLj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(bert_layer, max_len):\n",
        "\n",
        "  # defining 3 input layers for input_ids, attn_masks and type_ids\n",
        "    input_word_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
        "    input_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
        "    segment_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
        "  \n",
        "  #defining bert layer and passing the above layers as input\n",
        "    sequence_output, pooled_output= bert_layer([input_word_ids, input_mask, segment_ids])\n",
        "\n",
        "  #bert will generate pooled output and sequence output.\n",
        "  #\"pooled_output\" for classification tasks on an entire sentence.\n",
        "  #\"sequence_outputs\" for token-level output.\n",
        "    clf_output = pooled_output[:, 0, :]\n",
        "  \n",
        "  #these are neural network layers or fully connected newtork for classification\n",
        "    net = tf.keras.layers.Dense(64, activation='relu')(clf_output)\n",
        "    net = tf.keras.layers.Dropout(0.2)(net)\n",
        "    net = tf.keras.layers.Dense(32, activation='relu')(net)\n",
        "    net = tf.keras.layers.Dropout(0.2)(net)\n",
        "    out = tf.keras.layers.Dense(5, activation='softmax')(net)\n",
        "    \n",
        "    model = tf.keras.models.Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "hqAOCK1r47oG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(bert_layer, max_len=max_len)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfqUaygC6I3p",
        "outputId": "6c5159d0-6ef4-4331-9189-0366438fa72e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_word_ids (InputLayer)    [(None, 150)]        0           []                               \n",
            "                                                                                                  \n",
            " input_mask (InputLayer)        [(None, 150)]        0           []                               \n",
            "                                                                                                  \n",
            " segment_ids (InputLayer)       [(None, 150)]        0           []                               \n",
            "                                                                                                  \n",
            " keras_layer (KerasLayer)       [(None, 768),        109482241   ['input_word_ids[0][0]',         \n",
            "                                 (None, 150, 768)]                'input_mask[0][0]',             \n",
            "                                                                  'segment_ids[0][0]']            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 768)         0           ['keras_layer[0][1]']            \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 64)           49216       ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 64)           0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 32)           2080        ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 32)           0           ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 5)            165         ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,533,702\n",
            "Trainable params: 109,533,701\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compiling the model\n",
        "\n",
        " \n",
        "\n",
        "1.   Passing initial learning rate and Adam opimizer as per the official BERT documentation.\n",
        "2.   Categorical cross entropy as loss function since it is a multi class classification problem\n",
        "3.   Accuracy as the metric for evaluation"
      ],
      "metadata": {
        "id": "JEn-tSFlnbUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(tf.keras.optimizers.Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVV0mHdFng_L",
        "outputId": "91f85764-38b1-41a8-b388-49f71c3c04b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training of the model"
      ],
      "metadata": {
        "id": "7-ZHUmzrogKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, verbose=1)\n",
        "\n",
        "train_history = model.fit(\n",
        "    train_input, train_labels, \n",
        "    validation_split=0.2,\n",
        "    epochs=3,\n",
        "    callbacks=[checkpoint, earlystopping],\n",
        "    batch_size=32,\n",
        "    verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOLQ8kNXI74X",
        "outputId": "0bc6b869-b00c-41a1-dad5-1538e2d0f666"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "43/43 [==============================] - ETA: 0s - loss: 1.2303 - accuracy: 0.5163 \n",
            "Epoch 00001: val_accuracy improved from -inf to 0.82840, saving model to model.h5\n",
            "43/43 [==============================] - 2522s 58s/step - loss: 1.2303 - accuracy: 0.5163 - val_loss: 0.5828 - val_accuracy: 0.8284\n",
            "Epoch 2/3\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.4863 - accuracy: 0.8550 \n",
            "Epoch 00002: val_accuracy improved from 0.82840 to 0.96154, saving model to model.h5\n",
            "43/43 [==============================] - 2482s 58s/step - loss: 0.4863 - accuracy: 0.8550 - val_loss: 0.2070 - val_accuracy: 0.9615\n",
            "Epoch 3/3\n",
            "43/43 [==============================] - ETA: 0s - loss: 0.2520 - accuracy: 0.9438 \n",
            "Epoch 00003: val_accuracy improved from 0.96154 to 0.97929, saving model to model.h5\n",
            "43/43 [==============================] - 2481s 58s/step - loss: 0.2520 - accuracy: 0.9438 - val_loss: 0.1159 - val_accuracy: 0.9793\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#saving the final model\n",
        "saved_model_path = '/content/drive/MyDrive/Colab Notebooks/NLP_tranformers/model_bert'\n",
        "model.save(saved_model_path)\n",
        "\n",
        "\n",
        "#loading the model from gdrive\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/Colab Notebooks/NLP_tranformers/model_bert')"
      ],
      "metadata": {
        "id": "qwtfqO-o3V44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model predictions and classification report"
      ],
      "metadata": {
        "id": "J7EpsByvEMX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#predicting the test data set\n",
        "\n",
        "pred = model.predict(test_input)"
      ],
      "metadata": {
        "id": "X1NKc-L63mKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwrKo1Y-8qxT",
        "outputId": "ba784726-1545-47db-9f0f-3dd0471d712f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.9846197e-02, 8.3372557e-01, 6.3667528e-02, 4.8925965e-03,\n",
              "        7.7868134e-02],\n",
              "       [6.6133663e-03, 2.4175409e-03, 4.3157395e-03, 9.8305953e-01,\n",
              "        3.5938283e-03],\n",
              "       [2.7506005e-02, 6.9725037e-01, 8.1957400e-02, 5.1684557e-03,\n",
              "        1.8811782e-01],\n",
              "       ...,\n",
              "       [5.3339842e-04, 1.0936215e-03, 9.9692971e-01, 7.4326270e-04,\n",
              "        7.0013036e-04],\n",
              "       [3.8132637e-03, 1.6177733e-03, 4.5456463e-03, 9.8873222e-01,\n",
              "        1.2910572e-03],\n",
              "       [1.5885569e-03, 1.2344175e-03, 9.9463981e-01, 1.2706261e-03,\n",
              "        1.2667115e-03]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "VwOUxbzM9pUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = np.argmax(pred)\n",
        "print(classification_report(test_y, preds))"
      ],
      "metadata": {
        "id": "j-hMGtOY-LGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction1 = np.argmax(pred[0])\n",
        "prediction1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvUlgfNi8z0H",
        "outputId": "94edc978-5609-4c06-e7a6-34a1c690d4f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SHOpwm19IrA",
        "outputId": "baca0cd0-dc9a-453b-ac8c-17187f1d0a67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'business': 0, 'entertainment': 1, 'politics': 2, 'sport': 3, 'tech': 4}"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "actual1 = test.label.values[0]\n",
        "actual1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIG41CNhCHck",
        "outputId": "1925b295-a130-43f9-f5e3-57015f631bf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "actual2 = np.argmax(pred[1])\n",
        "actual2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SApmUC2eCVkO",
        "outputId": "da967224-d6ad-4ecb-d66d-394eb0cf3ec1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "verify2 = test.label.values[1]\n",
        "verify2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2POZ9hQCaP5",
        "outputId": "3acb4876-4cbd-4a61-ae1c-191868285a3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction3 = np.argmax(pred[400])\n",
        "prediction3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tilfSBaLCjvz",
        "outputId": "debbbffb-3be0-4f90-d786-a649b0077753"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "actual3 = test.label.values[400]\n",
        "actual3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4sjMHaKCpL3",
        "outputId": "fb4f5d19-24d2-486c-b25f-51e4ce7e133e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = np.argmax(pred,axis=1)\n",
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDsufd9_C6Px",
        "outputId": "5700ca82-42c4-4ad4-ac10-7bf3ac95a15a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 3, 1, 1, 2, 3, 4, 3, 0, 2, 2, 1, 3, 1, 3, 3, 0, 1, 2, 1, 1, 3,\n",
              "       0, 0, 0, 4, 3, 0, 2, 2, 1, 3, 0, 2, 3, 4, 1, 2, 0, 0, 4, 3, 4, 4,\n",
              "       0, 0, 1, 2, 0, 0, 3, 3, 3, 0, 4, 1, 1, 0, 0, 3, 4, 2, 3, 1, 0, 1,\n",
              "       2, 0, 1, 4, 1, 0, 2, 4, 0, 2, 3, 3, 2, 0, 1, 2, 3, 4, 1, 0, 3, 3,\n",
              "       0, 3, 4, 0, 3, 0, 2, 2, 2, 3, 3, 2, 1, 4, 0, 4, 3, 2, 2, 1, 3, 1,\n",
              "       0, 4, 4, 2, 3, 3, 0, 1, 0, 2, 4, 3, 2, 3, 2, 1, 3, 3, 3, 2, 3, 1,\n",
              "       0, 3, 4, 3, 3, 3, 0, 0, 1, 0, 0, 0, 3, 0, 2, 1, 3, 1, 4, 1, 2, 0,\n",
              "       0, 0, 1, 3, 1, 0, 1, 3, 0, 4, 0, 3, 3, 0, 2, 4, 1, 2, 1, 3, 0, 4,\n",
              "       0, 4, 2, 3, 4, 4, 4, 1, 1, 1, 4, 1, 1, 3, 0, 1, 2, 0, 3, 0, 0, 0,\n",
              "       3, 0, 3, 1, 3, 2, 2, 3, 0, 1, 2, 3, 3, 2, 4, 0, 1, 2, 0, 2, 4, 1,\n",
              "       0, 1, 0, 2, 1, 2, 1, 0, 3, 3, 0, 2, 0, 0, 1, 2, 0, 3, 4, 3, 2, 2,\n",
              "       4, 0, 3, 3, 2, 1, 2, 1, 4, 0, 2, 2, 1, 4, 0, 4, 1, 4, 0, 2, 2, 2,\n",
              "       4, 4, 2, 0, 0, 3, 2, 1, 0, 1, 1, 4, 4, 0, 0, 3, 3, 3, 3, 1, 1, 2,\n",
              "       0, 4, 4, 2, 4, 3, 1, 4, 3, 1, 1, 4, 3, 2, 0, 4, 2, 4, 2, 0, 0, 1,\n",
              "       3, 2, 0, 1, 2, 1, 3, 3, 2, 1, 3, 3, 4, 1, 3, 3, 1, 3, 4, 2, 2, 4,\n",
              "       2, 4, 0, 3, 3, 4, 0, 3, 4, 0, 4, 2, 2, 0, 2, 3, 0, 3, 0, 3, 4, 0,\n",
              "       3, 0, 0, 4, 3, 3, 0, 4, 2, 4, 3, 1, 3, 1, 3, 0, 4, 2, 2, 3, 2, 3,\n",
              "       1, 1, 4, 4, 1, 0, 2, 2, 1, 2, 2, 1, 0, 0, 4, 0, 1, 2, 3, 3, 2, 0,\n",
              "       3, 0, 0, 3, 0, 2, 0, 2, 4, 0, 1, 3, 0, 2, 3, 1, 3, 0, 4, 4, 3, 0,\n",
              "       0, 4, 2, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "actual = test.label.values\n",
        "actual"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySRElqprDM5C",
        "outputId": "1b864e7f-1837-4d7c-8490-90b5f0d4d5e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 3, 1, 1, 2, 3, 4, 3, 0, 2, 2, 1, 3, 1, 3, 3, 0, 1, 0, 1, 1, 3,\n",
              "       0, 0, 0, 4, 3, 0, 2, 2, 1, 3, 0, 2, 3, 4, 1, 2, 0, 0, 4, 3, 4, 4,\n",
              "       0, 0, 1, 2, 0, 0, 3, 3, 3, 0, 4, 1, 1, 0, 0, 3, 4, 2, 3, 4, 0, 1,\n",
              "       2, 0, 1, 4, 1, 0, 2, 4, 0, 2, 3, 3, 2, 0, 1, 2, 3, 4, 1, 0, 3, 3,\n",
              "       0, 3, 4, 0, 3, 0, 0, 2, 2, 3, 3, 2, 1, 4, 0, 4, 3, 2, 2, 1, 3, 1,\n",
              "       0, 4, 2, 2, 3, 3, 0, 1, 0, 2, 4, 3, 2, 3, 2, 1, 3, 3, 3, 2, 3, 1,\n",
              "       0, 3, 4, 3, 3, 3, 0, 0, 1, 0, 0, 0, 3, 0, 2, 1, 3, 1, 4, 1, 2, 0,\n",
              "       0, 0, 1, 3, 1, 0, 1, 3, 0, 4, 0, 3, 3, 0, 2, 4, 1, 2, 1, 3, 0, 4,\n",
              "       0, 4, 2, 3, 4, 4, 4, 1, 1, 1, 4, 1, 1, 3, 0, 1, 2, 0, 3, 0, 0, 0,\n",
              "       4, 0, 3, 1, 3, 2, 2, 3, 0, 1, 2, 3, 3, 2, 4, 0, 1, 2, 0, 2, 4, 1,\n",
              "       0, 1, 0, 2, 1, 2, 1, 1, 3, 3, 0, 2, 0, 4, 1, 2, 0, 3, 4, 3, 2, 2,\n",
              "       4, 0, 3, 3, 2, 1, 2, 1, 4, 0, 2, 2, 1, 4, 0, 4, 1, 4, 0, 2, 2, 2,\n",
              "       4, 4, 2, 0, 0, 3, 2, 1, 0, 1, 1, 4, 4, 0, 4, 3, 3, 3, 3, 1, 1, 2,\n",
              "       0, 4, 4, 2, 4, 3, 1, 4, 3, 1, 1, 4, 3, 2, 0, 4, 2, 4, 2, 0, 0, 1,\n",
              "       3, 2, 0, 1, 2, 1, 3, 3, 2, 1, 3, 3, 4, 1, 3, 3, 1, 3, 4, 2, 2, 4,\n",
              "       2, 4, 0, 3, 3, 4, 0, 3, 4, 0, 4, 2, 2, 0, 2, 3, 0, 3, 0, 3, 4, 0,\n",
              "       3, 0, 0, 0, 3, 3, 0, 4, 2, 4, 3, 1, 3, 1, 3, 0, 4, 2, 2, 3, 2, 3,\n",
              "       1, 1, 4, 4, 1, 0, 2, 2, 1, 2, 2, 1, 0, 0, 4, 0, 1, 2, 3, 3, 2, 0,\n",
              "       3, 4, 0, 3, 0, 2, 0, 2, 4, 0, 1, 3, 0, 2, 3, 1, 3, 0, 4, 4, 3, 0,\n",
              "       0, 4, 2, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(actual, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S50lSmvgDc5q",
        "outputId": "0f85f252-a37e-48cd-818a-fc3e0222dcb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96        99\n",
            "           1       0.99      0.99      0.99        76\n",
            "           2       0.98      0.99      0.98        81\n",
            "           3       0.99      1.00      0.99        99\n",
            "           4       0.97      0.93      0.95        68\n",
            "\n",
            "    accuracy                           0.98       423\n",
            "   macro avg       0.98      0.97      0.98       423\n",
            "weighted avg       0.98      0.98      0.98       423\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Another approach using preprocessing model from TF hub"
      ],
      "metadata": {
        "id": "w07NZ6RRsC0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeHMvILCsNQ5",
        "outputId": "142039c9-de8d-4055-a03a-bd50339cf3bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-text\n",
            "  Downloading tensorflow_text-2.7.3-cp37-cp37m-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow<2.8,>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text) (2.7.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text) (0.12.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (1.43.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (1.1.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (3.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (1.19.5)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (2.7.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (0.37.1)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (2.7.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (3.17.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (0.23.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (2.7.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (0.12.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (0.2.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (0.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (1.13.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (1.6.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (1.1.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (12.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (3.10.0.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.8,>=2.7.0->tensorflow-text) (1.5.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (0.6.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (4.10.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (3.1.1)\n",
            "Installing collected packages: tensorflow-text\n",
            "Successfully installed tensorflow-text-2.7.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "-3-NKptwsR2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#copied url from tensorflow hub\n",
        "\n",
        "\n",
        "preprocess_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\n",
        "encoder_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\""
      ],
      "metadata": {
        "id": "t45dnL3vsVCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#bert processing model which doesn't require to manually create the ID's as BERT input\n",
        "bert_preprocess_model = hub.KerasLayer(preprocess_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDrUemmbsYVU",
        "outputId": "924135c5-d845-4073-f869-cab995913ebd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:Downloading TF-Hub Module 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'.\n",
            "INFO:absl:Downloaded https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3, Total size: 1.96MB\n",
            "INFO:absl:Downloaded TF-Hub Module 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_word_ids2 = []\n",
        "all_masks2 = []\n",
        "all_type_ids2 = []\n",
        "def get_sentence_embeding(train):\n",
        "  for i,text in enumerate(train.article.values):\n",
        "    text = bert_preprocess_model([text])\n",
        "    all_word_ids2.append(text[\"input_word_ids\"])\n",
        "    all_masks2.append(text[\"input_mask\"])\n",
        "    all_type_ids2.append(text[\"input_type_ids\"])\n",
        "  return np.array(all_word_ids2), np.array(all_masks2), np.array(all_type_ids2)"
      ],
      "metadata": {
        "id": "WWirYGnlswW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train[:2]"
      ],
      "metadata": {
        "id": "Szjs4wlNTXE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.article.values[0]"
      ],
      "metadata": {
        "id": "VsTyzGCmx5Bx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.article.values[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "ybKOhjOfXp7L",
        "outputId": "dcb8a328-3582-4c85-820b-835c6e1eba76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'broadband fuels online expression  fast web access is encouraging more people to express themselves online, research suggests.  a quarter of broadband users in britain regularly upload content and have personal sites, according to a report by uk think-tank demos. it said that having an always-on, fast connection is changing the way people use the internet. more than five million households in the uk have broadband and that number is growing fast.  the demos report looked at the impact of broadband on people\\'s net habits. it found that more than half of those with broadband logged on to the web before breakfast. one in five even admitted to getting up in the middle of the night to browse the web.  more significantly, argues the report, broadband is encouraging people to take a more active role online. it found that one in five post something on the net everyday, ranging from comments or opinions on sites to uploading photographs. \"broadband is putting the \\'me\\' in media as it shifts power from institutions and into the hands of the individual,\" said john craig, co-author of the demos report. \"from self-diagnosis to online education, broadband creates social innovation that moves the debate beyond simple questions of access and speed.\" the demos report, entitled broadband britain: the end of asymmetry?, was commissioned by net provider aol. \"broadband is moving the perception of the internet as a piece of technology to an integral part of home life in the uk,\" said karen thomson, chief executive of aol uk, \"with many people spending time on their computers as automatically as they might switch on the television or radio.\" according to analysts nielsen//netratings, more than 50% of the 22.8 million uk net users regularly accessing the web from home each month are logging on at high speed they spend twice as long online than people on dial-up connections, viewing an average of 1,444 pages per month. the popularity of fast net access is growing, partly fuelled by fierce competition over prices and services. '"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "OCxsVVcjXs2j",
        "outputId": "aa9be8e3-cc1f-4b76-90f8-c3c04c4dc93d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-23b6a1a0-46ca-4d23-a03e-eb43edaba70c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article</th>\n",
              "      <th>category</th>\n",
              "      <th>label</th>\n",
              "      <th>data_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2108</th>\n",
              "      <td>broadband fuels online expression  fast web ac...</td>\n",
              "      <td>tech</td>\n",
              "      <td>4</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517</th>\n",
              "      <td>famed music director viotti dies  conductor ma...</td>\n",
              "      <td>entertainment</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-23b6a1a0-46ca-4d23-a03e-eb43edaba70c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-23b6a1a0-46ca-4d23-a03e-eb43edaba70c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-23b6a1a0-46ca-4d23-a03e-eb43edaba70c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                article  ... data_type\n",
              "2108  broadband fuels online expression  fast web ac...  ...     train\n",
              "517   famed music director viotti dies  conductor ma...  ...     train\n",
              "\n",
              "[2 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_input2 = get_sentence_embeding(train)"
      ],
      "metadata": {
        "id": "LxXDOf3Tx493"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is another approach to get the vector embedding of tokens. This can be passed to the bert model to build the classifier network"
      ],
      "metadata": {
        "id": "_kbTMDv9yCfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"Sentence : \", train.article.values[0])\n",
        "# print(\"-\"*30)\n",
        "print(\"Tokens : \", train.article.values[0])\n",
        "print(\"-\"*30)\n",
        "print(\"Word IDs : \", all_word_ids2[0])\n",
        "print(\"-\"*30)\n",
        "print(\"Input Masks : \", all_masks2[0])\n",
        "print(\"-\"*30)\n",
        "print(\"Type IDs : \", all_type_ids2[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCzb6h5EVkGV",
        "outputId": "15e40a31-2ddf-45e0-d6c4-b730d5ee3144"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens :  ['broadband', 'fuels', 'online', 'expression', 'fast', 'web', 'access', 'is', 'encouraging', 'more', 'people', 'to', 'express', 'themselves', 'online', 'research', 'suggests', 'a', 'quarter', 'of', 'broadband', 'users', 'in', 'britain', 'regularly', 'upload', 'content', 'and', 'have', 'personal', 'sites', 'according', 'to', 'a', 'report', 'by', 'uk', 'think-tank', 'demos', 'it', 'said', 'that', 'having', 'an', 'always-on', 'fast', 'connection', 'is', 'changing', 'the', 'way', 'people', 'use', 'the', 'internet', 'more', 'than', 'five', 'million', 'households', 'in', 'the', 'uk', 'have', 'broadband', 'and', 'that', 'number', 'is', 'growing', 'fast', 'the', 'demos', 'report', 'looked', 'at', 'the', 'impact', 'of', 'broadband', 'on', 'people', 'net', 'habits', 'it', 'found', 'that', 'more', 'than', 'half', 'of', 'those', 'with', 'broadband', 'logged', 'on', 'to', 'the', 'web', 'before', 'breakfast', 'one', 'in', 'five', 'even', 'admitted', 'to', 'getting', 'up', 'in', 'the', 'middle', 'of', 'the', 'night', 'to', 'browse', 'the', 'web', 'more', 'significantly', 'argues', 'the', 'report', 'broadband', 'is', 'encouraging', 'people', 'to', 'take', 'a', 'more', 'active', 'role', 'online', 'it', 'found', 'that', 'one', 'in', 'five', 'post', 'something', 'on', 'the', 'net', 'everyday', 'ranging', 'from', 'comments', 'or', 'opinions', 'on', 'sites', 'to', 'uploading', 'photographs', 'broadband', 'is', 'putting', 'the', 'in', 'media', 'as', 'it', 'shifts', 'power', 'from', 'institutions', 'and', 'into', 'the', 'hands', 'of', 'the', 'individual', 'said', 'john', 'craig', 'co-author', 'of', 'the', 'demos', 'report', 'from', 'self-diagnosis', 'to', 'online', 'education', 'broadband', 'creates', 'social', 'innovation', 'that', 'moves', 'the', 'debate', 'beyond', 'simple', 'questions', 'of', 'access', 'and', 'speed', 'the', 'demos', 'report', 'entitled', 'broadband', 'britain', 'the', 'end', 'of', 'asymmetry', 'was', 'commissioned', 'by', 'net', 'provider', 'aol', 'broadband', 'is', 'moving', 'the', 'perception', 'of', 'the', 'internet', 'as', 'a', 'piece', 'of', 'technology', 'to', 'an', 'integral', 'part', 'of', 'home', 'life', 'in', 'the', 'uk', 'said', 'karen', 'thomson', 'chief', 'executive', 'of', 'aol', 'uk', 'with', 'many', 'people', 'spending', 'time', 'on', 'their', 'computers', 'as', 'automatically', 'as', 'they', 'might', 'switch', 'on', 'the', 'television', 'or', 'radio', 'according', 'to', 'analysts', 'nielsen//netratings', 'more', 'than', 'of', 'the', 'million', 'uk', 'net', 'users', 'regularly', 'accessing', 'the', 'web', 'from', 'home', 'each', 'month', 'are', 'logging', 'on', 'at', 'high', 'speed', 'they', 'spend', 'twice', 'as', 'long', 'online', 'than', 'people', 'on', 'dial-up', 'connections', 'viewing', 'an', 'average', 'of', 'pages', 'per', 'month', 'the', 'popularity', 'of', 'fast', 'net', 'access', 'is', 'growing', 'partly', 'fuelled', 'by', 'fierce', 'competition', 'over', 'prices', 'and', 'services']\n",
            "------------------------------\n",
            "Word IDs :  tf.Tensor(\n",
            "[[  101 19595   102 ...     0     0     0]\n",
            " [  101 20145   102 ...     0     0     0]\n",
            " [  101  3784   102 ...     0     0     0]\n",
            " ...\n",
            " [  101  7597   102 ...     0     0     0]\n",
            " [  101  1998   102 ...     0     0     0]\n",
            " [  101  2578   102 ...     0     0     0]], shape=(331, 128), dtype=int32)\n",
            "------------------------------\n",
            "Input Masks :  tf.Tensor(\n",
            "[[1 1 1 ... 0 0 0]\n",
            " [1 1 1 ... 0 0 0]\n",
            " [1 1 1 ... 0 0 0]\n",
            " ...\n",
            " [1 1 1 ... 0 0 0]\n",
            " [1 1 1 ... 0 0 0]\n",
            " [1 1 1 ... 0 0 0]], shape=(331, 128), dtype=int32)\n",
            "------------------------------\n",
            "Type IDs :  tf.Tensor(\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]], shape=(331, 128), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PCEddwZLYNF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"Sentence : \", train.article.values[0])\n",
        "# print(\"-\"*30)\n",
        "print(\"Tokens : \", train.article.values[0])\n",
        "print(\"-\"*30)\n",
        "print(\"Word IDs : \", all_word_ids2[0])\n",
        "print(\"-\"*30)\n",
        "print(\"Input Masks : \", all_masks2[0])\n",
        "print(\"-\"*30)\n",
        "print(\"Type IDs : \", all_type_ids2[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9B1Sc7NsX96t",
        "outputId": "c9582494-9ec2-4af0-e0e9-66c9aa1f86f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens :  ['broadband', 'fuels', 'online', 'expression', 'fast', 'web', 'access', 'is', 'encouraging', 'more', 'people', 'to', 'express', 'themselves', 'online', 'research', 'suggests', 'a', 'quarter', 'of', 'broadband', 'users', 'in', 'britain', 'regularly', 'upload', 'content', 'and', 'have', 'personal', 'sites', 'according', 'to', 'a', 'report', 'by', 'uk', 'think-tank', 'demos', 'it', 'said', 'that', 'having', 'an', 'always-on', 'fast', 'connection', 'is', 'changing', 'the', 'way', 'people', 'use', 'the', 'internet', 'more', 'than', 'five', 'million', 'households', 'in', 'the', 'uk', 'have', 'broadband', 'and', 'that', 'number', 'is', 'growing', 'fast', 'the', 'demos', 'report', 'looked', 'at', 'the', 'impact', 'of', 'broadband', 'on', 'people', 'net', 'habits', 'it', 'found', 'that', 'more', 'than', 'half', 'of', 'those', 'with', 'broadband', 'logged', 'on', 'to', 'the', 'web', 'before', 'breakfast', 'one', 'in', 'five', 'even', 'admitted', 'to', 'getting', 'up', 'in', 'the', 'middle', 'of', 'the', 'night', 'to', 'browse', 'the', 'web', 'more', 'significantly', 'argues', 'the', 'report', 'broadband', 'is', 'encouraging', 'people', 'to', 'take', 'a', 'more', 'active', 'role', 'online', 'it', 'found', 'that', 'one', 'in', 'five', 'post', 'something', 'on', 'the', 'net', 'everyday', 'ranging', 'from', 'comments', 'or', 'opinions', 'on', 'sites', 'to', 'uploading', 'photographs', 'broadband', 'is', 'putting', 'the', 'in', 'media', 'as', 'it', 'shifts', 'power', 'from', 'institutions', 'and', 'into', 'the', 'hands', 'of', 'the', 'individual', 'said', 'john', 'craig', 'co-author', 'of', 'the', 'demos', 'report', 'from', 'self-diagnosis', 'to', 'online', 'education', 'broadband', 'creates', 'social', 'innovation', 'that', 'moves', 'the', 'debate', 'beyond', 'simple', 'questions', 'of', 'access', 'and', 'speed', 'the', 'demos', 'report', 'entitled', 'broadband', 'britain', 'the', 'end', 'of', 'asymmetry', 'was', 'commissioned', 'by', 'net', 'provider', 'aol', 'broadband', 'is', 'moving', 'the', 'perception', 'of', 'the', 'internet', 'as', 'a', 'piece', 'of', 'technology', 'to', 'an', 'integral', 'part', 'of', 'home', 'life', 'in', 'the', 'uk', 'said', 'karen', 'thomson', 'chief', 'executive', 'of', 'aol', 'uk', 'with', 'many', 'people', 'spending', 'time', 'on', 'their', 'computers', 'as', 'automatically', 'as', 'they', 'might', 'switch', 'on', 'the', 'television', 'or', 'radio', 'according', 'to', 'analysts', 'nielsen//netratings', 'more', 'than', 'of', 'the', 'million', 'uk', 'net', 'users', 'regularly', 'accessing', 'the', 'web', 'from', 'home', 'each', 'month', 'are', 'logging', 'on', 'at', 'high', 'speed', 'they', 'spend', 'twice', 'as', 'long', 'online', 'than', 'people', 'on', 'dial-up', 'connections', 'viewing', 'an', 'average', 'of', 'pages', 'per', 'month', 'the', 'popularity', 'of', 'fast', 'net', 'access', 'is', 'growing', 'partly', 'fuelled', 'by', 'fierce', 'competition', 'over', 'prices', 'and', 'services']\n",
            "------------------------------\n",
            "Word IDs :  tf.Tensor(\n",
            "[[  101 19595 20145  3784  3670  3435  4773  3229  2003 11434  2062  2111\n",
            "   2000  4671  3209  3784  1010  2470  6083  1012  1037  4284  1997 19595\n",
            "   5198  1999  3725  5570  2039 11066  4180  1998  2031  3167  4573  1010\n",
            "   2429  2000  1037  3189  2011  2866  2228  1011  4951 18267  1012  2009\n",
            "   2056  2008  2383  2019  2467  1011  2006  1010  3435  4434  2003  5278\n",
            "   1996  2126  2111  2224  1996  4274  1012  2062  2084  2274  2454  3911\n",
            "   1999  1996  2866  2031 19595  1998  2008  2193  2003  3652  3435  1012\n",
            "   1996 18267  3189  2246  2012  1996  4254  1997 19595  2006  2111  1005\n",
            "   1055  5658 14243  1012  2009  2179  2008  2062  2084  2431  1997  2216\n",
            "   2007 19595 26618  2006  2000  1996  4773  2077  6350  1012  2028  1999\n",
            "   2274  2130  4914  2000  2893  2039  1999   102]], shape=(1, 128), dtype=int32)\n",
            "------------------------------\n",
            "Input Masks :  tf.Tensor(\n",
            "[[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]], shape=(1, 128), dtype=int32)\n",
            "------------------------------\n",
            "Type IDs :  tf.Tensor(\n",
            "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]], shape=(1, 128), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Sentence : \", train.article.values[0])\n",
        "print(\"-\"*30)\n",
        "print(\"Word IDs : \", all_word_ids2[0])\n",
        "print(\"-\"*30)\n",
        "print(\"Input Masks : \", all_masks2[0])\n",
        "print(\"-\"*30)\n",
        "print(\"Type IDs : \", all_type_ids2[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRZzJSfGx47s",
        "outputId": "4b86767d-b951-4b71-8b01-d31d28f347d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence :  broadband fuels online expression  fast web access is encouraging more people to express themselves online, research suggests.  a quarter of broadband users in britain regularly upload content and have personal sites, according to a report by uk think-tank demos. it said that having an always-on, fast connection is changing the way people use the internet. more than five million households in the uk have broadband and that number is growing fast.  the demos report looked at the impact of broadband on people's net habits. it found that more than half of those with broadband logged on to the web before breakfast. one in five even admitted to getting up in the middle of the night to browse the web.  more significantly, argues the report, broadband is encouraging people to take a more active role online. it found that one in five post something on the net everyday, ranging from comments or opinions on sites to uploading photographs. \"broadband is putting the 'me' in media as it shifts power from institutions and into the hands of the individual,\" said john craig, co-author of the demos report. \"from self-diagnosis to online education, broadband creates social innovation that moves the debate beyond simple questions of access and speed.\" the demos report, entitled broadband britain: the end of asymmetry?, was commissioned by net provider aol. \"broadband is moving the perception of the internet as a piece of technology to an integral part of home life in the uk,\" said karen thomson, chief executive of aol uk, \"with many people spending time on their computers as automatically as they might switch on the television or radio.\" according to analysts nielsen//netratings, more than 50% of the 22.8 million uk net users regularly accessing the web from home each month are logging on at high speed they spend twice as long online than people on dial-up connections, viewing an average of 1,444 pages per month. the popularity of fast net access is growing, partly fuelled by fierce competition over prices and services. \n",
            "------------------------------\n",
            "Word IDs :  tf.Tensor(\n",
            "[[  101 19595 20145  3784  3670  3435  4773  3229  2003 11434  2062  2111\n",
            "   2000  4671  3209  3784  1010  2470  6083  1012  1037  4284  1997 19595\n",
            "   5198  1999  3725  5570  2039 11066  4180  1998  2031  3167  4573  1010\n",
            "   2429  2000  1037  3189  2011  2866  2228  1011  4951 18267  1012  2009\n",
            "   2056  2008  2383  2019  2467  1011  2006  1010  3435  4434  2003  5278\n",
            "   1996  2126  2111  2224  1996  4274  1012  2062  2084  2274  2454  3911\n",
            "   1999  1996  2866  2031 19595  1998  2008  2193  2003  3652  3435  1012\n",
            "   1996 18267  3189  2246  2012  1996  4254  1997 19595  2006  2111  1005\n",
            "   1055  5658 14243  1012  2009  2179  2008  2062  2084  2431  1997  2216\n",
            "   2007 19595 26618  2006  2000  1996  4773  2077  6350  1012  2028  1999\n",
            "   2274  2130  4914  2000  2893  2039  1999   102]], shape=(1, 128), dtype=int32)\n",
            "------------------------------\n",
            "Input Masks :  tf.Tensor(\n",
            "[[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]], shape=(1, 128), dtype=int32)\n",
            "------------------------------\n",
            "Type IDs :  tf.Tensor(\n",
            "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]], shape=(1, 128), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "_9QQcV6rSiUW",
        "outputId": "2ecfb1c2-1160-4a90-9510-00ae2f22d102"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Collecting nltk\n",
            "  Downloading nltk-3.6.7-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.62.3)\n",
            "Collecting regex>=2021.8.3\n",
            "  Downloading regex-2022.1.18-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (748 kB)\n",
            "\u001b[K     |████████████████████████████████| 748 kB 54.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.1.0)\n",
            "Installing collected packages: regex, nltk\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed nltk-3.6.7 regex-2022.1.18\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nltk",
                  "regex"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('perluniprops')\n",
        "\n",
        "from nltk.tokenize.moses import MosesDetokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "hdfzN4ztSjqs",
        "outputId": "a0dd84f3-5802-4f1c-de95-a8c880b164ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
            "[nltk_data]   Unzipping misc/perluniprops.zip.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-2319eb029e09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'perluniprops'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMosesDetokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk.tokenize.moses'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "C8HkYF8gSsw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4L4YRrGBSvlF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}